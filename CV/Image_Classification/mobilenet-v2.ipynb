{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-13T11:19:02.055441Z","iopub.status.busy":"2024-06-13T11:19:02.055095Z","iopub.status.idle":"2024-06-13T11:19:07.442621Z","shell.execute_reply":"2024-06-13T11:19:07.441630Z","shell.execute_reply.started":"2024-06-13T11:19:02.055413Z"},"trusted":true},"outputs":[],"source":["import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision.models import *"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:19:07.446228Z","iopub.status.busy":"2024-06-13T11:19:07.444402Z","iopub.status.idle":"2024-06-13T11:19:07.453513Z","shell.execute_reply":"2024-06-13T11:19:07.452597Z","shell.execute_reply.started":"2024-06-13T11:19:07.446197Z"},"trusted":true},"outputs":[],"source":["from torchvision import transforms\n","\n","transform = transforms.Compose([\n","    # you can add other transformations in this list\n","    transforms.ToTensor()\n","])"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:19:07.455032Z","iopub.status.busy":"2024-06-13T11:19:07.454737Z","iopub.status.idle":"2024-06-13T11:19:20.212821Z","shell.execute_reply":"2024-06-13T11:19:20.211827Z","shell.execute_reply.started":"2024-06-13T11:19:07.455006Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 26421880/26421880 [00:01<00:00, 13250925.26it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 29515/29515 [00:00<00:00, 209016.24it/s]\n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 4422102/4422102 [00:07<00:00, 598769.18it/s] \n"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/raw\n","\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n","Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"]},{"name":"stderr","output_type":"stream","text":["100%|██████████| 5148/5148 [00:00<00:00, 13683318.75it/s]"]},{"name":"stdout","output_type":"stream","text":["Extracting ./data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/raw\n","\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["mnist_train = torchvision.datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n","mnist_test = torchvision.datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:19:20.216100Z","iopub.status.busy":"2024-06-13T11:19:20.215639Z","iopub.status.idle":"2024-06-13T11:19:20.221971Z","shell.execute_reply":"2024-06-13T11:19:20.220972Z","shell.execute_reply.started":"2024-06-13T11:19:20.216067Z"},"trusted":true},"outputs":[],"source":["batch_size=64\n","trainloader = torch.utils.data.DataLoader(mnist_train, batch_size=batch_size,\n","                                          shuffle=True, num_workers=2)\n","testloader = torch.utils.data.DataLoader(mnist_test, batch_size=batch_size,\n","                                          shuffle=True, num_workers=2)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:19:20.223509Z","iopub.status.busy":"2024-06-13T11:19:20.223240Z","iopub.status.idle":"2024-06-13T11:19:20.231720Z","shell.execute_reply":"2024-06-13T11:19:20.230784Z","shell.execute_reply.started":"2024-06-13T11:19:20.223485Z"},"trusted":true},"outputs":[],"source":["device=\"cuda\""]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:19:20.233144Z","iopub.status.busy":"2024-06-13T11:19:20.232825Z","iopub.status.idle":"2024-06-13T11:19:22.711301Z","shell.execute_reply":"2024-06-13T11:19:22.710321Z","shell.execute_reply.started":"2024-06-13T11:19:20.233114Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n","100%|██████████| 13.6M/13.6M [00:00<00:00, 36.1MB/s]\n","/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n","100%|██████████| 83.3M/83.3M [00:01<00:00, 81.1MB/s]\n"]}],"source":["MobileNet = mobilenet_v2(pretrained = True)\n","MobileNet = resnet34(pretrained = True)\n","\n","for param in MobileNet.parameters():\n","    param.requires_grad = False"]},{"cell_type":"markdown","metadata":{},"source":["The MNIST dataset has input size of (28, 28, 1), but the pretrained mobile net v2 accepts input shape of (224, 224, 3).\n","Instead of just using Resize and interpolate, which due to the large size difference can cause the final image to be very blurry, I used FCN ideas of deconvolution to upsample the image."]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:19:22.712852Z","iopub.status.busy":"2024-06-13T11:19:22.712536Z","iopub.status.idle":"2024-06-13T11:19:22.721267Z","shell.execute_reply":"2024-06-13T11:19:22.720280Z","shell.execute_reply.started":"2024-06-13T11:19:22.712826Z"},"trusted":true},"outputs":[],"source":["class FCN_MobileNet(nn.Module):\n","    def __init__(self, pretrained, num_classes=10):\n","        super().__init__()\n","        self.convT1 = nn.ConvTranspose2d(1, 32, kernel_size=(3,3), stride=2)\n","        self.convT2 = nn.ConvTranspose2d(32, 32, kernel_size=(5,5), stride=4)\n","        self.conv1 = nn.Conv2d(32, 3, kernel_size=(6,6))\n","        self.pretrained = pretrained\n","        self.fc1 = nn.LazyLinear(512)\n","        self.fc2 = nn.Linear(512, num_classes)\n","        for param in self.pretrained.parameters():\n","            param.requires_grad = False\n","    def forward(self, x):\n","        x = self.convT1(x)\n","        x = self.convT2(x)\n","        x = self.conv1(x)\n","        x = self.pretrained(x)\n","        x = F.tanh(self.fc1(x))\n","        x = self.fc2(x)\n","#         print(x.shape)\n","        return x"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:19:22.722698Z","iopub.status.busy":"2024-06-13T11:19:22.722420Z","iopub.status.idle":"2024-06-13T11:19:22.926905Z","shell.execute_reply":"2024-06-13T11:19:22.925712Z","shell.execute_reply.started":"2024-06-13T11:19:22.722675Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n","  warnings.warn('Lazy modules are a new feature under heavy development '\n"]}],"source":["funni_net = FCN_MobileNet(MobileNet).to(device)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:19:22.928714Z","iopub.status.busy":"2024-06-13T11:19:22.928354Z","iopub.status.idle":"2024-06-13T11:19:22.935464Z","shell.execute_reply":"2024-06-13T11:19:22.934376Z","shell.execute_reply.started":"2024-06-13T11:19:22.928681Z"},"trusted":true},"outputs":[],"source":["import torch.optim as optim\n","\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(funni_net.parameters(), lr=0.0005) # take note to pass in the correct network for network.parameters()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-13T11:19:22.939532Z","iopub.status.busy":"2024-06-13T11:19:22.938925Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["[1,   100] loss: 0.7458684804\n","[1,   200] loss: 0.5284394974\n"]}],"source":["for epoch in range(10):  # loop over the dataset multiple times\n","\n","    running_loss = 0.0\n","    for i, data in enumerate(trainloader, 0):\n","        # get the inputs; data is a list of [inputs, labels]\n","        inputs, labels = data\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        # zero the parameter gradients\n","        optimizer.zero_grad()\n","\n","        # forward + backward + optimize\n","        outputs = funni_net(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        # print statistics\n","        running_loss += loss.item()\n","        if i % 100 == 99:    # print every 99 mini-batches\n","            print(f'[{epoch + 1}, {i + 1:5d}] loss: {running_loss / 99:.10f}')\n","            running_loss = 0.0\n","\n","print('Finished Training')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["correct = 0\n","total = 0\n","# since we're not training, we don't need to calculate the gradients for our outputs\n","with torch.no_grad():\n","    for data in testloader:\n","        images, labels = data\n","        images, labels = images.to(device), labels.to(device)\n","        # calculate outputs by running images through the network\n","        outputs = funni_net(images)\n","        # the class with the highest energy is what we choose as prediction\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print(f'Accuracy of the network on the 10000 test images: {100 * correct // total} %')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":3613373,"sourceId":6283815,"sourceType":"datasetVersion"}],"dockerImageVersionId":30733,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
