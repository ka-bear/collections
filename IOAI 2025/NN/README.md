# How to use
Follow the sequence of the syllabus, going from top to bottom then left to right. To illustarte, start with Perceptron Basics, reading the PDF slides then the notebook. Then move on to Gradient Descent, and so on...

# Syllabus

- Perceptron Basics (L03_perceptron_slides.pdf, Perceptron Basics.ipynb)
- Gradient Descent (L05_gradient-descent_slides.pdf)
- Backpropagation 
- Activation Functions (ReLU, Sigmoid, Tanh) 
- Cost Functions (MSE, MAE, Cross Entropy, etc.)

# People

- Yue Heng
- Zerui (again)
- Simu added the weights bias layer classes implementation 

