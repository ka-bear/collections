# Slides for NN

These slides are taken from [STAT 479](https://github.com/rasbt/stat479-deep-learning-ss19). The course (as Kabir mentioned) is an amazing source for learning the basics of AI.  

## L03_perceptron_slides.pdf

Focus on slides 14-19 (Definition of Perceptron) and slides 27-42 (Perceptron Convergence Theorem). Then proceed to the notebook about perceptrons in the parent folder.

## L05_gradient-descent_slides.pdf

Focus on slides 7-23 (Intro to Gradient Descent), 32-38 (Chain Rule, in case you don't have the intuition for that), and 50-55 (Linear Regression with applied Gradient Descent).  
Note that for 50-55, the differentiation is just an exercise to find the loss derivative in the context of the SSE loss. There's no need to memorize or work it out if you think you're good at math.  
Afterwards look at the relevant notebook in the parent folder.
