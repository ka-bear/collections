{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccc57fe5-173f-4849-8cc8-6dcd0424d720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                    text  label\n",
      "0      I grew up (b. 1965) watching and loving the Th...      0\n",
      "1      When I put this movie in my DVD player, and sa...      0\n",
      "2      Why do people who do not know what a particula...      0\n",
      "3      Even though I have great interest in Biblical ...      0\n",
      "4      Im a die hard Dads Army fan and nothing will e...      1\n",
      "...                                                  ...    ...\n",
      "39995  \"Western Union\" is something of a forgotten cl...      1\n",
      "39996  This movie is an incredible piece of work. It ...      1\n",
      "39997  My wife and I watched this movie because we pl...      0\n",
      "39998  When I first watched Flatliners, I was amazed....      1\n",
      "39999  Why would this film be so good, but only gross...      1\n",
      "\n",
      "[40000 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df = pd.read_csv(\"./data/movie.csv\")\n",
    "x = df.iloc[:,0]\n",
    "y = df.iloc[:,1]\n",
    "print(df)\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=42)\n",
    "vectorizer = TfidfVectorizer(stop_words=\"english\", lowercase=True, norm=\"l1\")\n",
    "x_train_v = vectorizer.fit_transform(x_train)\n",
    "x_test_v = vectorizer.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66ff858e-a10e-455a-930e-fc22a5ba8b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch 1\n",
      "Loss after mini-batch 1: 0.724707\n",
      "Loss after mini-batch 11: 0.699396\n",
      "Loss after mini-batch 21: 0.702613\n",
      "Loss after mini-batch 31: 0.701063\n",
      "Loss after mini-batch 41: 0.700152\n",
      "Loss after mini-batch 51: 0.698518\n",
      "Loss after mini-batch 61: 0.697607\n",
      "Loss after mini-batch 71: 0.697160\n",
      "Loss after mini-batch 81: 0.696545\n",
      "Loss after mini-batch 91: 0.695831\n",
      "Loss after mini-batch 101: 0.695973\n",
      "Loss after mini-batch 111: 0.695893\n",
      "Loss after mini-batch 121: 0.695691\n",
      "Loss after mini-batch 131: 0.695538\n",
      "Loss after mini-batch 141: 0.695378\n",
      "Loss after mini-batch 151: 0.695216\n",
      "Loss after mini-batch 161: 0.695148\n",
      "Loss after mini-batch 171: 0.695012\n",
      "Loss after mini-batch 181: 0.694972\n",
      "Loss after mini-batch 191: 0.694912\n",
      "Loss after mini-batch 201: 0.694849\n",
      "Loss after mini-batch 211: 0.694729\n",
      "Loss after mini-batch 221: 0.694659\n",
      "Loss after mini-batch 231: 0.694691\n",
      "Loss after mini-batch 241: 0.694636\n",
      "Loss after mini-batch 251: 0.694660\n",
      "Loss after mini-batch 261: 0.694661\n",
      "Loss after mini-batch 271: 0.694626\n",
      "Loss after mini-batch 281: 0.694564\n",
      "Loss after mini-batch 291: 0.694590\n",
      "Loss after mini-batch 301: 0.694539\n",
      "Loss after mini-batch 311: 0.694499\n",
      "Loss after mini-batch 321: 0.694341\n",
      "Loss after mini-batch 331: 0.694287\n",
      "Loss after mini-batch 341: 0.694348\n",
      "Loss after mini-batch 351: 0.694321\n",
      "Loss after mini-batch 361: 0.694268\n",
      "Loss after mini-batch 371: 0.694225\n",
      "Loss after mini-batch 381: 0.694231\n",
      "Loss after mini-batch 391: 0.694208\n",
      "Loss after mini-batch 401: 0.694186\n",
      "Loss after mini-batch 411: 0.694169\n",
      "Loss after mini-batch 421: 0.694173\n",
      "Loss after mini-batch 431: 0.694178\n",
      "Loss after mini-batch 441: 0.694164\n",
      "Loss after mini-batch 451: 0.694179\n",
      "Loss after mini-batch 461: 0.694162\n",
      "Loss after mini-batch 471: 0.694146\n",
      "Loss after mini-batch 481: 0.694170\n",
      "Loss after mini-batch 491: 0.694179\n",
      "Loss after mini-batch 501: 0.694169\n",
      "Loss after mini-batch 511: 0.694153\n",
      "Loss after mini-batch 521: 0.694151\n",
      "Loss after mini-batch 531: 0.694182\n",
      "Loss after mini-batch 541: 0.694185\n",
      "Loss after mini-batch 551: 0.694174\n",
      "Loss after mini-batch 561: 0.694137\n",
      "Loss after mini-batch 571: 0.694076\n",
      "Loss after mini-batch 581: 0.694114\n",
      "Loss after mini-batch 591: 0.694121\n",
      "Loss after mini-batch 601: 0.694092\n",
      "Loss after mini-batch 611: 0.694094\n",
      "Loss after mini-batch 621: 0.694077\n",
      "Loss after mini-batch 631: 0.694049\n",
      "Loss after mini-batch 641: 0.694045\n",
      "Loss after mini-batch 651: 0.694019\n",
      "Loss after mini-batch 661: 0.694060\n",
      "Loss after mini-batch 671: 0.694067\n",
      "Loss after mini-batch 681: 0.694086\n",
      "Loss after mini-batch 691: 0.694074\n",
      "Loss after mini-batch 701: 0.694045\n",
      "Loss after mini-batch 711: 0.694053\n",
      "Loss after mini-batch 721: 0.694046\n",
      "Loss after mini-batch 731: 0.694044\n",
      "Loss after mini-batch 741: 0.694051\n",
      "Loss after mini-batch 751: 0.694207\n",
      "Loss after mini-batch 761: 0.694181\n",
      "Loss after mini-batch 771: 0.694163\n",
      "Loss after mini-batch 781: 0.694158\n",
      "Loss after mini-batch 791: 0.694152\n",
      "Loss after mini-batch 801: 0.694154\n",
      "Loss after mini-batch 811: 0.694143\n",
      "Loss after mini-batch 821: 0.694124\n",
      "Loss after mini-batch 831: 0.694097\n",
      "Loss after mini-batch 841: 0.694103\n",
      "Loss after mini-batch 851: 0.694108\n",
      "Loss after mini-batch 861: 0.694097\n",
      "Loss after mini-batch 871: 0.694090\n",
      "Loss after mini-batch 881: 0.694077\n",
      "Loss after mini-batch 891: 0.694075\n",
      "Loss after mini-batch 901: 0.694069\n",
      "Loss after mini-batch 911: 0.694065\n",
      "Loss after mini-batch 921: 0.694080\n",
      "Loss after mini-batch 931: 0.694085\n",
      "Loss after mini-batch 941: 0.694080\n",
      "Loss after mini-batch 951: 0.694069\n",
      "Loss after mini-batch 961: 0.694063\n",
      "Loss after mini-batch 971: 0.694056\n",
      "Loss after mini-batch 981: 0.694049\n",
      "Loss after mini-batch 991: 0.694032\n",
      "Epoch 1 finished after 1000 batches.\n",
      "Starting Epoch 2\n",
      "Loss after mini-batch 1: 0.680103\n",
      "Loss after mini-batch 11: 0.693869\n",
      "Loss after mini-batch 21: 0.693327\n",
      "Loss after mini-batch 31: 0.692047\n",
      "Loss after mini-batch 41: 0.692003\n",
      "Loss after mini-batch 51: 0.693548\n",
      "Loss after mini-batch 61: 0.693770\n",
      "Loss after mini-batch 71: 0.694173\n",
      "Loss after mini-batch 81: 0.694184\n",
      "Loss after mini-batch 91: 0.694237\n",
      "Loss after mini-batch 101: 0.694159\n",
      "Loss after mini-batch 111: 0.694177\n",
      "Loss after mini-batch 121: 0.694114\n",
      "Loss after mini-batch 131: 0.694096\n",
      "Loss after mini-batch 141: 0.694057\n",
      "Loss after mini-batch 151: 0.693964\n",
      "Loss after mini-batch 161: 0.694242\n",
      "Loss after mini-batch 171: 0.694178\n",
      "Loss after mini-batch 181: 0.694213\n",
      "Loss after mini-batch 191: 0.694156\n",
      "Loss after mini-batch 201: 0.694137\n",
      "Loss after mini-batch 211: 0.694077\n",
      "Loss after mini-batch 221: 0.694008\n",
      "Loss after mini-batch 231: 0.693891\n",
      "Loss after mini-batch 241: 0.693788\n",
      "Loss after mini-batch 251: 0.693889\n",
      "Loss after mini-batch 261: 0.693973\n",
      "Loss after mini-batch 271: 0.693951\n",
      "Loss after mini-batch 281: 0.693834\n",
      "Loss after mini-batch 291: 0.693786\n",
      "Loss after mini-batch 301: 0.693989\n",
      "Loss after mini-batch 311: 0.693942\n",
      "Loss after mini-batch 321: 0.693920\n",
      "Loss after mini-batch 331: 0.693906\n",
      "Loss after mini-batch 341: 0.693909\n",
      "Loss after mini-batch 351: 0.693893\n",
      "Loss after mini-batch 361: 0.693885\n",
      "Loss after mini-batch 371: 0.693881\n",
      "Loss after mini-batch 381: 0.693858\n",
      "Loss after mini-batch 391: 0.693838\n",
      "Loss after mini-batch 401: 0.693816\n",
      "Loss after mini-batch 411: 0.693796\n",
      "Loss after mini-batch 421: 0.693817\n",
      "Loss after mini-batch 431: 0.693810\n",
      "Loss after mini-batch 441: 0.693782\n",
      "Loss after mini-batch 451: 0.693776\n",
      "Loss after mini-batch 461: 0.693749\n",
      "Loss after mini-batch 471: 0.693784\n",
      "Loss after mini-batch 481: 0.693785\n",
      "Loss after mini-batch 491: 0.693772\n",
      "Loss after mini-batch 501: 0.693764\n",
      "Loss after mini-batch 511: 0.693753\n",
      "Loss after mini-batch 521: 0.693725\n",
      "Loss after mini-batch 531: 0.693724\n",
      "Loss after mini-batch 541: 0.693753\n",
      "Loss after mini-batch 551: 0.693767\n",
      "Loss after mini-batch 561: 0.693752\n",
      "Loss after mini-batch 571: 0.693721\n",
      "Loss after mini-batch 581: 0.693768\n",
      "Loss after mini-batch 591: 0.693786\n",
      "Loss after mini-batch 601: 0.693792\n",
      "Loss after mini-batch 611: 0.693777\n",
      "Loss after mini-batch 621: 0.693783\n",
      "Loss after mini-batch 631: 0.693769\n",
      "Loss after mini-batch 641: 0.693779\n",
      "Loss after mini-batch 651: 0.693785\n",
      "Loss after mini-batch 661: 0.693753\n",
      "Loss after mini-batch 671: 0.693830\n",
      "Loss after mini-batch 681: 0.693820\n",
      "Loss after mini-batch 691: 0.693785\n",
      "Loss after mini-batch 701: 0.693812\n",
      "Loss after mini-batch 711: 0.693816\n",
      "Loss after mini-batch 721: 0.693767\n",
      "Loss after mini-batch 731: 0.693747\n",
      "Loss after mini-batch 741: 0.693792\n",
      "Loss after mini-batch 751: 0.693810\n",
      "Loss after mini-batch 761: 0.693819\n",
      "Loss after mini-batch 771: 0.693806\n",
      "Loss after mini-batch 781: 0.693825\n",
      "Loss after mini-batch 791: 0.693752\n",
      "Loss after mini-batch 801: 0.693808\n",
      "Loss after mini-batch 811: 0.693823\n",
      "Loss after mini-batch 821: 0.693780\n",
      "Loss after mini-batch 831: 0.693795\n",
      "Loss after mini-batch 841: 0.693860\n",
      "Loss after mini-batch 851: 0.693863\n",
      "Loss after mini-batch 861: 0.693852\n",
      "Loss after mini-batch 871: 0.693853\n",
      "Loss after mini-batch 881: 0.693848\n",
      "Loss after mini-batch 891: 0.693844\n",
      "Loss after mini-batch 901: 0.693835\n",
      "Loss after mini-batch 911: 0.693841\n",
      "Loss after mini-batch 921: 0.693854\n",
      "Loss after mini-batch 931: 0.693845\n",
      "Loss after mini-batch 941: 0.693839\n",
      "Loss after mini-batch 951: 0.693803\n",
      "Loss after mini-batch 961: 0.693910\n",
      "Loss after mini-batch 971: 0.693895\n",
      "Loss after mini-batch 981: 0.693888\n",
      "Loss after mini-batch 991: 0.693869\n",
      "Epoch 2 finished after 1000 batches.\n",
      "Starting Epoch 3\n",
      "Loss after mini-batch 1: 0.697382\n",
      "Loss after mini-batch 11: 0.690915\n",
      "Loss after mini-batch 21: 0.689768\n",
      "Loss after mini-batch 31: 0.691445\n",
      "Loss after mini-batch 41: 0.692683\n",
      "Loss after mini-batch 51: 0.693097\n",
      "Loss after mini-batch 61: 0.693094\n",
      "Loss after mini-batch 71: 0.692513\n",
      "Loss after mini-batch 81: 0.693523\n",
      "Loss after mini-batch 91: 0.693612\n",
      "Loss after mini-batch 101: 0.693648\n",
      "Loss after mini-batch 111: 0.693455\n",
      "Loss after mini-batch 121: 0.693815\n",
      "Loss after mini-batch 131: 0.693746\n",
      "Loss after mini-batch 141: 0.693640\n",
      "Loss after mini-batch 151: 0.693307\n",
      "Loss after mini-batch 161: 0.693405\n",
      "Loss after mini-batch 171: 0.693492\n",
      "Loss after mini-batch 181: 0.693770\n",
      "Loss after mini-batch 191: 0.693754\n",
      "Loss after mini-batch 201: 0.693734\n",
      "Loss after mini-batch 211: 0.693719\n",
      "Loss after mini-batch 221: 0.693602\n",
      "Loss after mini-batch 231: 0.693592\n",
      "Loss after mini-batch 241: 0.693634\n",
      "Loss after mini-batch 251: 0.693693\n",
      "Loss after mini-batch 261: 0.693682\n",
      "Loss after mini-batch 271: 0.693738\n",
      "Loss after mini-batch 281: 0.693715\n",
      "Loss after mini-batch 291: 0.693702\n",
      "Loss after mini-batch 301: 0.693715\n",
      "Loss after mini-batch 311: 0.693666\n",
      "Loss after mini-batch 321: 0.693579\n",
      "Loss after mini-batch 331: 0.693665\n",
      "Loss after mini-batch 341: 0.693644\n",
      "Loss after mini-batch 351: 0.693665\n",
      "Loss after mini-batch 361: 0.693636\n",
      "Loss after mini-batch 371: 0.693626\n",
      "Loss after mini-batch 381: 0.693667\n",
      "Loss after mini-batch 391: 0.693701\n",
      "Loss after mini-batch 401: 0.693707\n",
      "Loss after mini-batch 411: 0.693751\n",
      "Loss after mini-batch 421: 0.693738\n",
      "Loss after mini-batch 431: 0.693732\n",
      "Loss after mini-batch 441: 0.693727\n",
      "Loss after mini-batch 451: 0.693678\n",
      "Loss after mini-batch 461: 0.693748\n",
      "Loss after mini-batch 471: 0.693784\n",
      "Loss after mini-batch 481: 0.693774\n",
      "Loss after mini-batch 491: 0.693753\n",
      "Loss after mini-batch 501: 0.693776\n",
      "Loss after mini-batch 511: 0.693761\n",
      "Loss after mini-batch 521: 0.693752\n",
      "Loss after mini-batch 531: 0.693744\n",
      "Loss after mini-batch 541: 0.693766\n",
      "Loss after mini-batch 551: 0.693763\n",
      "Loss after mini-batch 561: 0.693759\n",
      "Loss after mini-batch 571: 0.693784\n",
      "Loss after mini-batch 581: 0.693814\n",
      "Loss after mini-batch 591: 0.693782\n",
      "Loss after mini-batch 601: 0.693785\n",
      "Loss after mini-batch 611: 0.693778\n",
      "Loss after mini-batch 621: 0.693779\n",
      "Loss after mini-batch 631: 0.693783\n",
      "Loss after mini-batch 641: 0.693794\n",
      "Loss after mini-batch 651: 0.693775\n",
      "Loss after mini-batch 661: 0.693819\n",
      "Loss after mini-batch 671: 0.693815\n",
      "Loss after mini-batch 681: 0.693799\n",
      "Loss after mini-batch 691: 0.693810\n",
      "Loss after mini-batch 701: 0.693795\n",
      "Loss after mini-batch 711: 0.693792\n",
      "Loss after mini-batch 721: 0.693785\n",
      "Loss after mini-batch 731: 0.693781\n",
      "Loss after mini-batch 741: 0.693785\n",
      "Loss after mini-batch 751: 0.693802\n",
      "Loss after mini-batch 761: 0.693809\n",
      "Loss after mini-batch 771: 0.693799\n",
      "Loss after mini-batch 781: 0.693781\n",
      "Loss after mini-batch 791: 0.693754\n",
      "Loss after mini-batch 801: 0.693779\n",
      "Loss after mini-batch 811: 0.693772\n",
      "Loss after mini-batch 821: 0.693778\n",
      "Loss after mini-batch 831: 0.693766\n",
      "Loss after mini-batch 841: 0.693797\n",
      "Loss after mini-batch 851: 0.693793\n",
      "Loss after mini-batch 861: 0.693792\n",
      "Loss after mini-batch 871: 0.693787\n",
      "Loss after mini-batch 881: 0.693795\n",
      "Loss after mini-batch 891: 0.693777\n",
      "Loss after mini-batch 901: 0.693788\n",
      "Loss after mini-batch 911: 0.693816\n",
      "Loss after mini-batch 921: 0.693807\n",
      "Loss after mini-batch 931: 0.693802\n",
      "Loss after mini-batch 941: 0.693789\n",
      "Loss after mini-batch 951: 0.693802\n",
      "Loss after mini-batch 961: 0.693832\n",
      "Loss after mini-batch 971: 0.693830\n",
      "Loss after mini-batch 981: 0.693831\n",
      "Loss after mini-batch 991: 0.693820\n",
      "Epoch 3 finished after 1000 batches.\n",
      "Starting Epoch 4\n",
      "Loss after mini-batch 1: 0.699717\n",
      "Loss after mini-batch 11: 0.694057\n",
      "Loss after mini-batch 21: 0.693535\n",
      "Loss after mini-batch 31: 0.694211\n",
      "Loss after mini-batch 41: 0.694013\n",
      "Loss after mini-batch 51: 0.693907\n",
      "Loss after mini-batch 61: 0.693829\n",
      "Loss after mini-batch 71: 0.693801\n",
      "Loss after mini-batch 81: 0.693734\n",
      "Loss after mini-batch 91: 0.693694\n",
      "Loss after mini-batch 101: 0.693751\n",
      "Loss after mini-batch 111: 0.693676\n",
      "Loss after mini-batch 121: 0.693754\n",
      "Loss after mini-batch 131: 0.693827\n",
      "Loss after mini-batch 141: 0.693712\n",
      "Loss after mini-batch 151: 0.693897\n",
      "Loss after mini-batch 161: 0.693891\n",
      "Loss after mini-batch 171: 0.693908\n",
      "Loss after mini-batch 181: 0.693879\n",
      "Loss after mini-batch 191: 0.693821\n",
      "Loss after mini-batch 201: 0.693796\n",
      "Loss after mini-batch 211: 0.693766\n",
      "Loss after mini-batch 221: 0.693776\n",
      "Loss after mini-batch 231: 0.693739\n",
      "Loss after mini-batch 241: 0.693690\n",
      "Loss after mini-batch 251: 0.693829\n",
      "Loss after mini-batch 261: 0.693913\n",
      "Loss after mini-batch 271: 0.693896\n",
      "Loss after mini-batch 281: 0.693897\n",
      "Loss after mini-batch 291: 0.693873\n",
      "Loss after mini-batch 301: 0.693890\n",
      "Loss after mini-batch 311: 0.693842\n",
      "Loss after mini-batch 321: 0.693833\n",
      "Loss after mini-batch 331: 0.693829\n",
      "Loss after mini-batch 341: 0.693821\n",
      "Loss after mini-batch 351: 0.693806\n",
      "Loss after mini-batch 361: 0.693807\n",
      "Loss after mini-batch 371: 0.693721\n",
      "Loss after mini-batch 381: 0.693790\n",
      "Loss after mini-batch 391: 0.693777\n",
      "Loss after mini-batch 401: 0.693748\n",
      "Loss after mini-batch 411: 0.693741\n",
      "Loss after mini-batch 421: 0.693681\n",
      "Loss after mini-batch 431: 0.693644\n",
      "Loss after mini-batch 441: 0.693774\n",
      "Loss after mini-batch 451: 0.693758\n",
      "Loss after mini-batch 461: 0.693728\n",
      "Loss after mini-batch 471: 0.693711\n",
      "Loss after mini-batch 481: 0.693688\n",
      "Loss after mini-batch 491: 0.693669\n",
      "Loss after mini-batch 501: 0.693706\n",
      "Loss after mini-batch 511: 0.693701\n",
      "Loss after mini-batch 521: 0.693668\n",
      "Loss after mini-batch 531: 0.693669\n",
      "Loss after mini-batch 541: 0.693634\n",
      "Loss after mini-batch 551: 0.693711\n",
      "Loss after mini-batch 561: 0.693672\n",
      "Loss after mini-batch 571: 0.693633\n",
      "Loss after mini-batch 581: 0.693529\n",
      "Loss after mini-batch 591: 0.693511\n",
      "Loss after mini-batch 601: 0.693528\n",
      "Loss after mini-batch 611: 0.693546\n",
      "Loss after mini-batch 621: 0.693524\n",
      "Loss after mini-batch 631: 0.693546\n",
      "Loss after mini-batch 641: 0.693546\n",
      "Loss after mini-batch 651: 0.693509\n",
      "Loss after mini-batch 661: 0.693500\n",
      "Loss after mini-batch 671: 0.693574\n",
      "Loss after mini-batch 681: 0.693571\n",
      "Loss after mini-batch 691: 0.693575\n",
      "Loss after mini-batch 701: 0.693553\n",
      "Loss after mini-batch 711: 0.693575\n",
      "Loss after mini-batch 721: 0.693560\n",
      "Loss after mini-batch 731: 0.693585\n",
      "Loss after mini-batch 741: 0.693583\n",
      "Loss after mini-batch 751: 0.693564\n",
      "Loss after mini-batch 761: 0.693610\n",
      "Loss after mini-batch 771: 0.693630\n",
      "Loss after mini-batch 781: 0.693618\n",
      "Loss after mini-batch 791: 0.693633\n",
      "Loss after mini-batch 801: 0.693619\n",
      "Loss after mini-batch 811: 0.693649\n",
      "Loss after mini-batch 821: 0.693654\n",
      "Loss after mini-batch 831: 0.693649\n",
      "Loss after mini-batch 841: 0.693655\n",
      "Loss after mini-batch 851: 0.693644\n",
      "Loss after mini-batch 861: 0.693643\n",
      "Loss after mini-batch 871: 0.693651\n",
      "Loss after mini-batch 881: 0.693655\n",
      "Loss after mini-batch 891: 0.693651\n",
      "Loss after mini-batch 901: 0.693651\n",
      "Loss after mini-batch 911: 0.693645\n",
      "Loss after mini-batch 921: 0.693602\n",
      "Loss after mini-batch 931: 0.693634\n",
      "Loss after mini-batch 941: 0.693684\n",
      "Loss after mini-batch 951: 0.693678\n",
      "Loss after mini-batch 961: 0.693684\n",
      "Loss after mini-batch 971: 0.693727\n",
      "Loss after mini-batch 981: 0.693723\n",
      "Loss after mini-batch 991: 0.693732\n",
      "Epoch 4 finished after 1000 batches.\n",
      "Starting Epoch 5\n",
      "Loss after mini-batch 1: 0.692973\n",
      "Loss after mini-batch 11: 0.693233\n",
      "Loss after mini-batch 21: 0.693136\n",
      "Loss after mini-batch 31: 0.693445\n",
      "Loss after mini-batch 41: 0.693074\n",
      "Loss after mini-batch 51: 0.692908\n",
      "Loss after mini-batch 61: 0.693243\n",
      "Loss after mini-batch 71: 0.693196\n",
      "Loss after mini-batch 81: 0.693410\n",
      "Loss after mini-batch 91: 0.693363\n",
      "Loss after mini-batch 101: 0.693150\n",
      "Loss after mini-batch 111: 0.693347\n",
      "Loss after mini-batch 121: 0.693413\n",
      "Loss after mini-batch 131: 0.693428\n",
      "Loss after mini-batch 141: 0.693494\n",
      "Loss after mini-batch 151: 0.693519\n",
      "Loss after mini-batch 161: 0.693412\n",
      "Loss after mini-batch 171: 0.693492\n",
      "Loss after mini-batch 181: 0.693495\n",
      "Loss after mini-batch 191: 0.693466\n",
      "Loss after mini-batch 201: 0.693474\n",
      "Loss after mini-batch 211: 0.693519\n",
      "Loss after mini-batch 221: 0.693562\n",
      "Loss after mini-batch 231: 0.693556\n",
      "Loss after mini-batch 241: 0.693547\n",
      "Loss after mini-batch 251: 0.693423\n",
      "Loss after mini-batch 261: 0.693468\n",
      "Loss after mini-batch 271: 0.693521\n",
      "Loss after mini-batch 281: 0.693565\n",
      "Loss after mini-batch 291: 0.693555\n",
      "Loss after mini-batch 301: 0.693577\n",
      "Loss after mini-batch 311: 0.693595\n",
      "Loss after mini-batch 321: 0.693626\n",
      "Loss after mini-batch 331: 0.693611\n",
      "Loss after mini-batch 341: 0.693600\n",
      "Loss after mini-batch 351: 0.693598\n",
      "Loss after mini-batch 361: 0.693646\n",
      "Loss after mini-batch 371: 0.693642\n",
      "Loss after mini-batch 381: 0.693630\n",
      "Loss after mini-batch 391: 0.693640\n",
      "Loss after mini-batch 401: 0.693586\n",
      "Loss after mini-batch 411: 0.693593\n",
      "Loss after mini-batch 421: 0.693523\n",
      "Loss after mini-batch 431: 0.693536\n",
      "Loss after mini-batch 441: 0.693623\n",
      "Loss after mini-batch 451: 0.693662\n",
      "Loss after mini-batch 461: 0.693632\n",
      "Loss after mini-batch 471: 0.693671\n",
      "Loss after mini-batch 481: 0.693654\n",
      "Loss after mini-batch 491: 0.693655\n",
      "Loss after mini-batch 501: 0.693642\n",
      "Loss after mini-batch 511: 0.693649\n",
      "Loss after mini-batch 521: 0.693636\n",
      "Loss after mini-batch 531: 0.693631\n",
      "Loss after mini-batch 541: 0.693625\n",
      "Loss after mini-batch 551: 0.693628\n",
      "Loss after mini-batch 561: 0.693619\n",
      "Loss after mini-batch 571: 0.693646\n",
      "Loss after mini-batch 581: 0.693639\n",
      "Loss after mini-batch 591: 0.693633\n",
      "Loss after mini-batch 601: 0.693631\n",
      "Loss after mini-batch 611: 0.693631\n",
      "Loss after mini-batch 621: 0.693627\n",
      "Loss after mini-batch 631: 0.693615\n",
      "Loss after mini-batch 641: 0.693508\n",
      "Loss after mini-batch 651: 0.693506\n",
      "Loss after mini-batch 661: 0.693584\n",
      "Loss after mini-batch 671: 0.693563\n",
      "Loss after mini-batch 681: 0.693571\n",
      "Loss after mini-batch 691: 0.693560\n",
      "Loss after mini-batch 701: 0.693560\n",
      "Loss after mini-batch 711: 0.693556\n",
      "Loss after mini-batch 721: 0.693558\n",
      "Loss after mini-batch 731: 0.693557\n",
      "Loss after mini-batch 741: 0.693560\n",
      "Loss after mini-batch 751: 0.693549\n",
      "Loss after mini-batch 761: 0.693540\n",
      "Loss after mini-batch 771: 0.693540\n",
      "Loss after mini-batch 781: 0.693586\n",
      "Loss after mini-batch 791: 0.693583\n",
      "Loss after mini-batch 801: 0.693586\n",
      "Loss after mini-batch 811: 0.693572\n",
      "Loss after mini-batch 821: 0.693577\n",
      "Loss after mini-batch 831: 0.693581\n",
      "Loss after mini-batch 841: 0.693562\n",
      "Loss after mini-batch 851: 0.693549\n",
      "Loss after mini-batch 861: 0.693588\n",
      "Loss after mini-batch 871: 0.693577\n",
      "Loss after mini-batch 881: 0.693572\n",
      "Loss after mini-batch 891: 0.693572\n",
      "Loss after mini-batch 901: 0.693570\n",
      "Loss after mini-batch 911: 0.693586\n",
      "Loss after mini-batch 921: 0.693580\n",
      "Loss after mini-batch 931: 0.693567\n",
      "Loss after mini-batch 941: 0.693591\n",
      "Loss after mini-batch 951: 0.693598\n",
      "Loss after mini-batch 961: 0.693594\n",
      "Loss after mini-batch 971: 0.693597\n",
      "Loss after mini-batch 981: 0.693604\n",
      "Loss after mini-batch 991: 0.693589\n",
      "Epoch 5 finished after 1000 batches.\n",
      "Starting Epoch 6\n",
      "Loss after mini-batch 1: 0.693156\n",
      "Loss after mini-batch 11: 0.693052\n",
      "Loss after mini-batch 21: 0.691296\n",
      "Loss after mini-batch 31: 0.693992\n",
      "Loss after mini-batch 41: 0.692244\n",
      "Loss after mini-batch 51: 0.692497\n",
      "Loss after mini-batch 61: 0.691992\n",
      "Loss after mini-batch 71: 0.692881\n",
      "Loss after mini-batch 81: 0.692988\n",
      "Loss after mini-batch 91: 0.692774\n",
      "Loss after mini-batch 101: 0.692833\n",
      "Loss after mini-batch 111: 0.693216\n",
      "Loss after mini-batch 121: 0.693229\n",
      "Loss after mini-batch 131: 0.693217\n",
      "Loss after mini-batch 141: 0.693328\n",
      "Loss after mini-batch 151: 0.693283\n",
      "Loss after mini-batch 161: 0.693048\n",
      "Loss after mini-batch 171: 0.692958\n",
      "Loss after mini-batch 181: 0.693154\n",
      "Loss after mini-batch 191: 0.693085\n",
      "Loss after mini-batch 201: 0.692892\n",
      "Loss after mini-batch 211: 0.693003\n",
      "Loss after mini-batch 221: 0.692901\n",
      "Loss after mini-batch 231: 0.692844\n",
      "Loss after mini-batch 241: 0.692687\n",
      "Loss after mini-batch 251: 0.692897\n",
      "Loss after mini-batch 261: 0.692869\n",
      "Loss after mini-batch 271: 0.692970\n",
      "Loss after mini-batch 281: 0.693001\n",
      "Loss after mini-batch 291: 0.693006\n",
      "Loss after mini-batch 301: 0.693189\n",
      "Loss after mini-batch 311: 0.693217\n",
      "Loss after mini-batch 321: 0.693236\n",
      "Loss after mini-batch 331: 0.693240\n",
      "Loss after mini-batch 341: 0.693228\n",
      "Loss after mini-batch 351: 0.693262\n",
      "Loss after mini-batch 361: 0.693250\n",
      "Loss after mini-batch 371: 0.693270\n",
      "Loss after mini-batch 381: 0.693273\n",
      "Loss after mini-batch 391: 0.693258\n",
      "Loss after mini-batch 401: 0.693258\n",
      "Loss after mini-batch 411: 0.693296\n",
      "Loss after mini-batch 421: 0.693296\n",
      "Loss after mini-batch 431: 0.693298\n",
      "Loss after mini-batch 441: 0.693283\n",
      "Loss after mini-batch 451: 0.693297\n",
      "Loss after mini-batch 461: 0.693301\n",
      "Loss after mini-batch 471: 0.693302\n",
      "Loss after mini-batch 481: 0.693286\n",
      "Loss after mini-batch 491: 0.693292\n",
      "Loss after mini-batch 501: 0.693291\n",
      "Loss after mini-batch 511: 0.693277\n",
      "Loss after mini-batch 521: 0.693263\n",
      "Loss after mini-batch 531: 0.693260\n",
      "Loss after mini-batch 541: 0.693279\n",
      "Loss after mini-batch 551: 0.693253\n",
      "Loss after mini-batch 561: 0.693185\n",
      "Loss after mini-batch 571: 0.693136\n",
      "Loss after mini-batch 581: 0.693182\n",
      "Loss after mini-batch 591: 0.693134\n",
      "Loss after mini-batch 601: 0.693158\n",
      "Loss after mini-batch 611: 0.693174\n",
      "Loss after mini-batch 621: 0.693212\n",
      "Loss after mini-batch 631: 0.693221\n",
      "Loss after mini-batch 641: 0.693259\n",
      "Loss after mini-batch 651: 0.693272\n",
      "Loss after mini-batch 661: 0.693276\n",
      "Loss after mini-batch 671: 0.693267\n",
      "Loss after mini-batch 681: 0.693246\n",
      "Loss after mini-batch 691: 0.693264\n",
      "Loss after mini-batch 701: 0.693240\n",
      "Loss after mini-batch 711: 0.693267\n",
      "Loss after mini-batch 721: 0.693265\n",
      "Loss after mini-batch 731: 0.693254\n",
      "Loss after mini-batch 741: 0.693246\n",
      "Loss after mini-batch 751: 0.693260\n",
      "Loss after mini-batch 761: 0.693265\n",
      "Loss after mini-batch 771: 0.693265\n",
      "Loss after mini-batch 781: 0.693266\n",
      "Stopping epoch 6 early after 784 batches due to no improvement.\n",
      "Epoch 6 finished after 784 batches.\n",
      "Starting Epoch 7\n",
      "Loss after mini-batch 1: 0.693908\n",
      "Loss after mini-batch 11: 0.693000\n",
      "Loss after mini-batch 21: 0.693710\n",
      "Loss after mini-batch 31: 0.693585\n",
      "Loss after mini-batch 41: 0.692935\n",
      "Loss after mini-batch 51: 0.693140\n",
      "Loss after mini-batch 61: 0.693323\n",
      "Loss after mini-batch 71: 0.693503\n",
      "Loss after mini-batch 81: 0.693402\n",
      "Loss after mini-batch 91: 0.693494\n",
      "Loss after mini-batch 101: 0.693440\n",
      "Loss after mini-batch 111: 0.693312\n",
      "Loss after mini-batch 121: 0.693056\n",
      "Loss after mini-batch 131: 0.692929\n",
      "Loss after mini-batch 141: 0.693177\n",
      "Loss after mini-batch 151: 0.693546\n",
      "Loss after mini-batch 161: 0.693555\n",
      "Loss after mini-batch 171: 0.693744\n",
      "Loss after mini-batch 181: 0.693708\n",
      "Loss after mini-batch 191: 0.693795\n",
      "Loss after mini-batch 201: 0.693775\n",
      "Loss after mini-batch 211: 0.693693\n",
      "Loss after mini-batch 221: 0.693641\n",
      "Loss after mini-batch 231: 0.693640\n",
      "Loss after mini-batch 241: 0.693664\n",
      "Loss after mini-batch 251: 0.693649\n",
      "Loss after mini-batch 261: 0.693661\n",
      "Loss after mini-batch 271: 0.693645\n",
      "Loss after mini-batch 281: 0.693600\n",
      "Loss after mini-batch 291: 0.693691\n",
      "Loss after mini-batch 301: 0.693524\n",
      "Loss after mini-batch 311: 0.693453\n",
      "Loss after mini-batch 321: 0.693678\n",
      "Loss after mini-batch 331: 0.693634\n",
      "Loss after mini-batch 341: 0.693593\n",
      "Loss after mini-batch 351: 0.693568\n",
      "Loss after mini-batch 361: 0.693648\n",
      "Loss after mini-batch 371: 0.693645\n",
      "Loss after mini-batch 381: 0.693642\n",
      "Loss after mini-batch 391: 0.693613\n",
      "Loss after mini-batch 401: 0.693629\n",
      "Loss after mini-batch 411: 0.693613\n",
      "Loss after mini-batch 421: 0.693645\n",
      "Loss after mini-batch 431: 0.693676\n",
      "Loss after mini-batch 441: 0.693660\n",
      "Loss after mini-batch 451: 0.693707\n",
      "Loss after mini-batch 461: 0.693720\n",
      "Loss after mini-batch 471: 0.693702\n",
      "Loss after mini-batch 481: 0.693701\n",
      "Loss after mini-batch 491: 0.693692\n",
      "Loss after mini-batch 501: 0.693720\n",
      "Loss after mini-batch 511: 0.693704\n",
      "Loss after mini-batch 521: 0.693709\n",
      "Loss after mini-batch 531: 0.693724\n",
      "Loss after mini-batch 541: 0.693714\n",
      "Loss after mini-batch 551: 0.693710\n",
      "Loss after mini-batch 561: 0.693712\n",
      "Loss after mini-batch 571: 0.693720\n",
      "Loss after mini-batch 581: 0.693716\n",
      "Loss after mini-batch 591: 0.693722\n",
      "Loss after mini-batch 601: 0.693707\n",
      "Loss after mini-batch 611: 0.693706\n",
      "Loss after mini-batch 621: 0.693702\n",
      "Loss after mini-batch 631: 0.693682\n",
      "Loss after mini-batch 641: 0.693702\n",
      "Loss after mini-batch 651: 0.693697\n",
      "Loss after mini-batch 661: 0.693702\n",
      "Loss after mini-batch 671: 0.693689\n",
      "Loss after mini-batch 681: 0.693658\n",
      "Loss after mini-batch 691: 0.693711\n",
      "Loss after mini-batch 701: 0.693714\n",
      "Loss after mini-batch 711: 0.693714\n",
      "Loss after mini-batch 721: 0.693690\n",
      "Loss after mini-batch 731: 0.693690\n",
      "Loss after mini-batch 741: 0.693726\n",
      "Loss after mini-batch 751: 0.693710\n",
      "Loss after mini-batch 761: 0.693726\n",
      "Loss after mini-batch 771: 0.693730\n",
      "Loss after mini-batch 781: 0.693733\n",
      "Loss after mini-batch 791: 0.693730\n",
      "Loss after mini-batch 801: 0.693745\n",
      "Loss after mini-batch 811: 0.693753\n",
      "Loss after mini-batch 821: 0.693746\n",
      "Loss after mini-batch 831: 0.693739\n",
      "Loss after mini-batch 841: 0.693722\n",
      "Loss after mini-batch 851: 0.693740\n",
      "Loss after mini-batch 861: 0.693753\n",
      "Loss after mini-batch 871: 0.693748\n",
      "Loss after mini-batch 881: 0.693744\n",
      "Loss after mini-batch 891: 0.693726\n",
      "Loss after mini-batch 901: 0.693732\n",
      "Loss after mini-batch 911: 0.693715\n",
      "Loss after mini-batch 921: 0.693736\n",
      "Loss after mini-batch 931: 0.693730\n",
      "Stopping epoch 7 early after 935 batches due to no improvement.\n",
      "Epoch 7 finished after 935 batches.\n",
      "Starting Epoch 8\n",
      "Loss after mini-batch 1: 0.693541\n",
      "Loss after mini-batch 11: 0.693585\n",
      "Loss after mini-batch 21: 0.692754\n",
      "Loss after mini-batch 31: 0.693574\n",
      "Loss after mini-batch 41: 0.693560\n",
      "Loss after mini-batch 51: 0.693675\n",
      "Loss after mini-batch 61: 0.693182\n",
      "Loss after mini-batch 71: 0.692059\n",
      "Loss after mini-batch 81: 0.692707\n",
      "Loss after mini-batch 91: 0.693258\n",
      "Loss after mini-batch 101: 0.693668\n",
      "Loss after mini-batch 111: 0.693605\n",
      "Loss after mini-batch 121: 0.693756\n",
      "Loss after mini-batch 131: 0.693861\n",
      "Loss after mini-batch 141: 0.693805\n",
      "Loss after mini-batch 151: 0.693739\n",
      "Loss after mini-batch 161: 0.693760\n",
      "Loss after mini-batch 171: 0.693733\n",
      "Loss after mini-batch 181: 0.693622\n",
      "Loss after mini-batch 191: 0.693685\n",
      "Loss after mini-batch 201: 0.693528\n",
      "Loss after mini-batch 211: 0.693559\n",
      "Loss after mini-batch 221: 0.693727\n",
      "Loss after mini-batch 231: 0.693709\n",
      "Loss after mini-batch 241: 0.693700\n",
      "Loss after mini-batch 251: 0.693658\n",
      "Loss after mini-batch 261: 0.693680\n",
      "Loss after mini-batch 271: 0.693718\n",
      "Loss after mini-batch 281: 0.693743\n",
      "Loss after mini-batch 291: 0.693742\n",
      "Loss after mini-batch 301: 0.693734\n",
      "Loss after mini-batch 311: 0.693707\n",
      "Loss after mini-batch 321: 0.693686\n",
      "Loss after mini-batch 331: 0.693596\n",
      "Loss after mini-batch 341: 0.693568\n",
      "Loss after mini-batch 351: 0.693675\n",
      "Loss after mini-batch 361: 0.693685\n",
      "Loss after mini-batch 371: 0.693656\n",
      "Loss after mini-batch 381: 0.693685\n",
      "Loss after mini-batch 391: 0.693709\n",
      "Loss after mini-batch 401: 0.693693\n",
      "Loss after mini-batch 411: 0.693690\n",
      "Loss after mini-batch 421: 0.693640\n",
      "Loss after mini-batch 431: 0.693655\n",
      "Loss after mini-batch 441: 0.693641\n",
      "Loss after mini-batch 451: 0.693637\n",
      "Loss after mini-batch 461: 0.693634\n",
      "Loss after mini-batch 471: 0.693629\n",
      "Loss after mini-batch 481: 0.693626\n",
      "Loss after mini-batch 491: 0.693643\n",
      "Loss after mini-batch 501: 0.693635\n",
      "Loss after mini-batch 511: 0.693626\n",
      "Loss after mini-batch 521: 0.693624\n",
      "Loss after mini-batch 531: 0.693613\n",
      "Loss after mini-batch 541: 0.693616\n",
      "Loss after mini-batch 551: 0.693610\n",
      "Loss after mini-batch 561: 0.693601\n",
      "Loss after mini-batch 571: 0.693577\n",
      "Loss after mini-batch 581: 0.693564\n",
      "Loss after mini-batch 591: 0.693537\n",
      "Loss after mini-batch 601: 0.693569\n",
      "Loss after mini-batch 611: 0.693563\n",
      "Loss after mini-batch 621: 0.693563\n",
      "Loss after mini-batch 631: 0.693561\n",
      "Loss after mini-batch 641: 0.693556\n",
      "Loss after mini-batch 651: 0.693549\n",
      "Loss after mini-batch 661: 0.693551\n",
      "Loss after mini-batch 671: 0.693554\n",
      "Loss after mini-batch 681: 0.693553\n",
      "Loss after mini-batch 691: 0.693531\n",
      "Loss after mini-batch 701: 0.693506\n",
      "Loss after mini-batch 711: 0.693532\n",
      "Loss after mini-batch 721: 0.693515\n",
      "Loss after mini-batch 731: 0.693557\n",
      "Loss after mini-batch 741: 0.693569\n",
      "Loss after mini-batch 751: 0.693568\n",
      "Loss after mini-batch 761: 0.693565\n",
      "Loss after mini-batch 771: 0.693560\n",
      "Loss after mini-batch 781: 0.693533\n",
      "Loss after mini-batch 791: 0.693511\n",
      "Loss after mini-batch 801: 0.693543\n",
      "Loss after mini-batch 811: 0.693567\n",
      "Loss after mini-batch 821: 0.693548\n",
      "Loss after mini-batch 831: 0.693517\n",
      "Loss after mini-batch 841: 0.693542\n",
      "Loss after mini-batch 851: 0.693510\n",
      "Loss after mini-batch 861: 0.693510\n",
      "Loss after mini-batch 871: 0.693524\n",
      "Loss after mini-batch 881: 0.693523\n",
      "Loss after mini-batch 891: 0.693518\n",
      "Loss after mini-batch 901: 0.693494\n",
      "Loss after mini-batch 911: 0.693494\n",
      "Loss after mini-batch 921: 0.693506\n",
      "Loss after mini-batch 931: 0.693515\n",
      "Loss after mini-batch 941: 0.693517\n",
      "Loss after mini-batch 951: 0.693514\n",
      "Stopping epoch 8 early after 951 batches due to no improvement.\n",
      "Epoch 8 finished after 951 batches.\n",
      "Starting Epoch 9\n",
      "Loss after mini-batch 1: 0.693491\n",
      "Loss after mini-batch 11: 0.693238\n",
      "Loss after mini-batch 21: 0.693052\n",
      "Loss after mini-batch 31: 0.693500\n",
      "Loss after mini-batch 41: 0.693333\n",
      "Loss after mini-batch 51: 0.693585\n",
      "Loss after mini-batch 61: 0.693495\n",
      "Loss after mini-batch 71: 0.693255\n",
      "Loss after mini-batch 81: 0.693134\n",
      "Loss after mini-batch 91: 0.693021\n",
      "Loss after mini-batch 101: 0.693222\n",
      "Loss after mini-batch 111: 0.693407\n",
      "Loss after mini-batch 121: 0.693415\n",
      "Loss after mini-batch 131: 0.693382\n",
      "Loss after mini-batch 141: 0.693339\n",
      "Loss after mini-batch 151: 0.693426\n",
      "Loss after mini-batch 161: 0.693417\n",
      "Loss after mini-batch 171: 0.693386\n",
      "Loss after mini-batch 181: 0.693431\n",
      "Loss after mini-batch 191: 0.693492\n",
      "Loss after mini-batch 201: 0.693530\n",
      "Loss after mini-batch 211: 0.693341\n",
      "Loss after mini-batch 221: 0.693558\n",
      "Loss after mini-batch 231: 0.693572\n",
      "Loss after mini-batch 241: 0.693525\n",
      "Loss after mini-batch 251: 0.693555\n",
      "Loss after mini-batch 261: 0.693629\n",
      "Loss after mini-batch 271: 0.693634\n",
      "Loss after mini-batch 281: 0.693646\n",
      "Loss after mini-batch 291: 0.693650\n",
      "Loss after mini-batch 301: 0.693634\n",
      "Loss after mini-batch 311: 0.693592\n",
      "Loss after mini-batch 321: 0.693570\n",
      "Loss after mini-batch 331: 0.693566\n",
      "Loss after mini-batch 341: 0.693591\n",
      "Loss after mini-batch 351: 0.693588\n",
      "Loss after mini-batch 361: 0.693589\n",
      "Loss after mini-batch 371: 0.693580\n",
      "Loss after mini-batch 381: 0.693574\n",
      "Loss after mini-batch 391: 0.693566\n",
      "Loss after mini-batch 401: 0.693512\n",
      "Loss after mini-batch 411: 0.693523\n",
      "Loss after mini-batch 421: 0.693501\n",
      "Loss after mini-batch 431: 0.693554\n",
      "Loss after mini-batch 441: 0.693552\n",
      "Loss after mini-batch 451: 0.693550\n",
      "Loss after mini-batch 461: 0.693542\n",
      "Loss after mini-batch 471: 0.693542\n",
      "Loss after mini-batch 481: 0.693575\n",
      "Loss after mini-batch 491: 0.693569\n",
      "Loss after mini-batch 501: 0.693555\n",
      "Loss after mini-batch 511: 0.693494\n",
      "Loss after mini-batch 521: 0.693563\n",
      "Loss after mini-batch 531: 0.693604\n",
      "Loss after mini-batch 541: 0.693602\n",
      "Loss after mini-batch 551: 0.693602\n",
      "Loss after mini-batch 561: 0.693565\n",
      "Loss after mini-batch 571: 0.693519\n",
      "Loss after mini-batch 581: 0.693521\n",
      "Loss after mini-batch 591: 0.693548\n",
      "Loss after mini-batch 601: 0.693569\n",
      "Loss after mini-batch 611: 0.693561\n",
      "Loss after mini-batch 621: 0.693546\n",
      "Loss after mini-batch 631: 0.693553\n",
      "Loss after mini-batch 641: 0.693568\n",
      "Loss after mini-batch 651: 0.693579\n",
      "Loss after mini-batch 661: 0.693575\n",
      "Loss after mini-batch 671: 0.693568\n",
      "Loss after mini-batch 681: 0.693575\n",
      "Loss after mini-batch 691: 0.693576\n",
      "Loss after mini-batch 701: 0.693584\n",
      "Loss after mini-batch 711: 0.693589\n",
      "Loss after mini-batch 721: 0.693595\n",
      "Loss after mini-batch 731: 0.693561\n",
      "Loss after mini-batch 741: 0.693547\n",
      "Loss after mini-batch 751: 0.693567\n",
      "Loss after mini-batch 761: 0.693585\n",
      "Loss after mini-batch 771: 0.693583\n",
      "Loss after mini-batch 781: 0.693582\n",
      "Loss after mini-batch 791: 0.693518\n",
      "Loss after mini-batch 801: 0.693526\n",
      "Loss after mini-batch 811: 0.693562\n",
      "Loss after mini-batch 821: 0.693592\n",
      "Loss after mini-batch 831: 0.693583\n",
      "Loss after mini-batch 841: 0.693581\n",
      "Loss after mini-batch 851: 0.693580\n",
      "Loss after mini-batch 861: 0.693571\n",
      "Loss after mini-batch 871: 0.693565\n",
      "Loss after mini-batch 881: 0.693525\n",
      "Loss after mini-batch 891: 0.693541\n",
      "Loss after mini-batch 901: 0.693568\n",
      "Loss after mini-batch 911: 0.693562\n",
      "Loss after mini-batch 921: 0.693547\n",
      "Loss after mini-batch 931: 0.693541\n",
      "Loss after mini-batch 941: 0.693517\n",
      "Loss after mini-batch 951: 0.693532\n",
      "Loss after mini-batch 961: 0.693538\n",
      "Loss after mini-batch 971: 0.693522\n",
      "Loss after mini-batch 981: 0.693532\n",
      "Loss after mini-batch 991: 0.693535\n",
      "Epoch 9 finished after 1000 batches.\n",
      "Starting Epoch 10\n",
      "Loss after mini-batch 1: 0.689619\n",
      "Loss after mini-batch 11: 0.690183\n",
      "Loss after mini-batch 21: 0.693413\n",
      "Loss after mini-batch 31: 0.694218\n",
      "Loss after mini-batch 41: 0.693307\n",
      "Loss after mini-batch 51: 0.694612\n",
      "Loss after mini-batch 61: 0.694842\n",
      "Loss after mini-batch 71: 0.694571\n",
      "Loss after mini-batch 81: 0.694383\n",
      "Loss after mini-batch 91: 0.694273\n",
      "Loss after mini-batch 101: 0.694152\n",
      "Loss after mini-batch 111: 0.694192\n",
      "Loss after mini-batch 121: 0.694102\n",
      "Loss after mini-batch 131: 0.694264\n",
      "Loss after mini-batch 141: 0.694173\n",
      "Loss after mini-batch 151: 0.694130\n",
      "Loss after mini-batch 161: 0.694088\n",
      "Loss after mini-batch 171: 0.693920\n",
      "Loss after mini-batch 181: 0.694036\n",
      "Loss after mini-batch 191: 0.694283\n",
      "Loss after mini-batch 201: 0.694258\n",
      "Loss after mini-batch 211: 0.694183\n",
      "Loss after mini-batch 221: 0.694169\n",
      "Loss after mini-batch 231: 0.694089\n",
      "Loss after mini-batch 241: 0.694081\n",
      "Loss after mini-batch 251: 0.694065\n",
      "Loss after mini-batch 261: 0.694030\n",
      "Loss after mini-batch 271: 0.694025\n",
      "Loss after mini-batch 281: 0.693999\n",
      "Loss after mini-batch 291: 0.693977\n",
      "Loss after mini-batch 301: 0.693951\n",
      "Loss after mini-batch 311: 0.693930\n",
      "Loss after mini-batch 321: 0.693920\n",
      "Loss after mini-batch 331: 0.693906\n",
      "Loss after mini-batch 341: 0.693892\n",
      "Loss after mini-batch 351: 0.693860\n",
      "Loss after mini-batch 361: 0.693840\n",
      "Loss after mini-batch 371: 0.693814\n",
      "Loss after mini-batch 381: 0.693833\n",
      "Loss after mini-batch 391: 0.693806\n",
      "Loss after mini-batch 401: 0.693803\n",
      "Loss after mini-batch 411: 0.693787\n",
      "Loss after mini-batch 421: 0.693784\n",
      "Loss after mini-batch 431: 0.693777\n",
      "Loss after mini-batch 441: 0.693760\n",
      "Loss after mini-batch 451: 0.693770\n",
      "Loss after mini-batch 461: 0.693798\n",
      "Loss after mini-batch 471: 0.693895\n",
      "Loss after mini-batch 481: 0.693876\n",
      "Loss after mini-batch 491: 0.693899\n",
      "Loss after mini-batch 501: 0.694016\n",
      "Loss after mini-batch 511: 0.694004\n",
      "Loss after mini-batch 521: 0.693976\n",
      "Loss after mini-batch 531: 0.693998\n",
      "Loss after mini-batch 541: 0.693989\n",
      "Loss after mini-batch 551: 0.693958\n",
      "Loss after mini-batch 561: 0.693999\n",
      "Loss after mini-batch 571: 0.693987\n",
      "Loss after mini-batch 581: 0.693978\n",
      "Loss after mini-batch 591: 0.693966\n",
      "Loss after mini-batch 601: 0.693977\n",
      "Loss after mini-batch 611: 0.693968\n",
      "Loss after mini-batch 621: 0.693943\n",
      "Loss after mini-batch 631: 0.693944\n",
      "Loss after mini-batch 641: 0.693924\n",
      "Loss after mini-batch 651: 0.693931\n",
      "Loss after mini-batch 661: 0.693934\n",
      "Loss after mini-batch 671: 0.693925\n",
      "Loss after mini-batch 681: 0.693885\n",
      "Loss after mini-batch 691: 0.693915\n",
      "Loss after mini-batch 701: 0.693903\n",
      "Loss after mini-batch 711: 0.693920\n",
      "Loss after mini-batch 721: 0.693911\n",
      "Loss after mini-batch 731: 0.693871\n",
      "Loss after mini-batch 741: 0.693881\n",
      "Loss after mini-batch 751: 0.693839\n",
      "Loss after mini-batch 761: 0.693833\n",
      "Loss after mini-batch 771: 0.693805\n",
      "Loss after mini-batch 781: 0.693823\n",
      "Loss after mini-batch 791: 0.693774\n",
      "Loss after mini-batch 801: 0.693696\n",
      "Loss after mini-batch 811: 0.693698\n",
      "Loss after mini-batch 821: 0.693734\n",
      "Loss after mini-batch 831: 0.693698\n",
      "Loss after mini-batch 841: 0.693729\n",
      "Loss after mini-batch 851: 0.693711\n",
      "Loss after mini-batch 861: 0.693711\n",
      "Loss after mini-batch 871: 0.693711\n",
      "Stopping epoch 10 early after 879 batches due to no improvement.\n",
      "Epoch 10 finished after 879 batches.\n",
      "Training has completed\n"
     ]
    }
   ],
   "source": [
    "x_train_tensor = torch.tensor(x_train_v.toarray(), dtype=torch.float32)\n",
    "x_test_tensor = torch.tensor(x_test_v.toarray(), dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)  # Long dtype for classification\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(x_train_tensor, y_train_tensor)\n",
    "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Define MLP Model\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Initialize model\n",
    "input_size = x_train_tensor.shape[1]  # Match TF-IDF feature size\n",
    "mlp = MLP(input_size, 2)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "loss_function = nn.CrossEntropyLoss()  # For classification\n",
    "optimizer = torch.optim.SGD(mlp.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "\n",
    "# Training loop with early stopping within an epoch\n",
    "num_epochs = 5\n",
    "epsilon = 1e-5  # Stopping threshold\n",
    "prev_loss = float('inf')  # Initialize previous loss to a large value\n",
    "patience_batches = 10  # Stop if no improvement in the last N batches\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Starting Epoch {epoch+1}')\n",
    "    current_loss = 0.0\n",
    "    batch_no_improve = 0  # Counter to track stagnation\n",
    "\n",
    "    for i, (inputs, targets) in enumerate(trainloader, 0):\n",
    "        inputs, targets = inputs.float(), targets.long()  # Ensure correct types\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = mlp(inputs)\n",
    "\n",
    "        loss = loss_function(outputs, targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        current_loss += loss.item()\n",
    "        avg_loss = current_loss / (i + 1)  # Moving average loss\n",
    "\n",
    "        if i % 10 == 0:  # Print loss every 10 batches\n",
    "            print(f'Loss after mini-batch {i+1}: {avg_loss:.6f}')\n",
    "\n",
    "        # Early stopping within an epoch (stop if loss stabilizes)\n",
    "        if abs(prev_loss - avg_loss) < epsilon:\n",
    "            batch_no_improve += 1\n",
    "            if batch_no_improve >= patience_batches:\n",
    "                print(f\"Stopping epoch {epoch+1} early after {i+1} batches due to no improvement.\")\n",
    "                break\n",
    "        else:\n",
    "            batch_no_improve = 0  # Reset counter if loss improves\n",
    "\n",
    "        prev_loss = avg_loss  # Update loss for next check\n",
    "\n",
    "    print(f\"Epoch {epoch+1} finished after {i+1} batches.\")\n",
    "\n",
    "print(\"Training has completed\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "322086f9-862a-4359-9d0d-53e496e26a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLP(\n",
       "  (layers): Sequential(\n",
       "    (0): Linear(in_features=84479, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=32, out_features=16, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=16, out_features=8, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=8, out_features=4, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=4, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b69f42a-ae30-449d-be8d-131e61fe1ca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.30407515 -0.32051724]\n",
      " [-0.30408213 -0.32052079]\n",
      " [-0.30404875 -0.32050344]\n",
      " ...\n",
      " [-0.30408004 -0.32052046]\n",
      " [-0.30407214 -0.32051522]\n",
      " [-0.30408233 -0.32052064]]\n",
      "[0 1 0 ... 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "outputs = mlp(x_test_tensor)\n",
    "predicted_labels = outputs.squeeze().tolist()\n",
    "\n",
    "predicted_labels = np.array(predicted_labels)\n",
    "test_targets = np.array(y_test_tensor)\n",
    "\n",
    "print(predicted_labels)\n",
    "print(test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02e160a-1065-4ddf-ac34-ecd0853f91c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
