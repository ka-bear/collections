{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -U huggingface datasets evaluate\n!python -m spacy download en_core_web_sm > /dev/null\n!python -m spacy download de_core_news_sm > /dev/null","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:51:50.985958Z","iopub.execute_input":"2024-06-15T11:51:50.986344Z","iopub.status.idle":"2024-06-15T11:52:56.969108Z","shell.execute_reply.started":"2024-06-15T11:51:50.986310Z","shell.execute_reply":"2024-06-15T11:52:56.968029Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting huggingface\n  Downloading huggingface-0.0.1-py3-none-any.whl.metadata (2.9 kB)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.19.2)\nCollecting datasets\n  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\nCollecting evaluate\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nCollecting pyarrow>=15.0.0 (from datasets)\n  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.1)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.5.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets) (2024.3.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.23.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nDownloading huggingface-0.0.1-py3-none-any.whl (2.5 kB)\nDownloading datasets-2.20.0-py3-none-any.whl (547 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: huggingface, pyarrow, datasets, evaluate\n  Attempting uninstall: pyarrow\n    Found existing installation: pyarrow 14.0.2\n    Uninstalling pyarrow-14.0.2:\n      Successfully uninstalled pyarrow-14.0.2\n  Attempting uninstall: datasets\n    Found existing installation: datasets 2.19.2\n    Uninstalling datasets-2.19.2:\n      Successfully uninstalled datasets-2.19.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.4.1 requires cubinlinker, which is not installed.\ncudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.4.1 requires ptxcompiler, which is not installed.\ncuml 24.4.0 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.4.1 requires cupy-cuda11x>=12.0.0, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\nbeatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.1 which is incompatible.\ncudf 24.4.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\ncudf 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask==2024.1.1, but you have dask 2024.5.2 which is incompatible.\nrapids-dask-dependency 24.4.1a0 requires dask-expr==0.4.0, but you have dask-expr 1.1.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed datasets-2.20.0 evaluate-0.4.2 huggingface-0.0.1 pyarrow-16.1.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport random\nimport numpy as np\nimport spacy\nimport datasets\nimport torchtext\nimport tqdm\nimport evaluate","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:52:56.971128Z","iopub.execute_input":"2024-06-15T11:52:56.971502Z","iopub.status.idle":"2024-06-15T11:53:13.756815Z","shell.execute_reply.started":"2024-06-15T11:52:56.971466Z","shell.execute_reply":"2024-06-15T11:53:13.756069Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-06-15 11:53:03.651341: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-15 11:53:03.651438: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-15 11:53:03.760039: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"device = \"cuda\"","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:53:13.757791Z","iopub.execute_input":"2024-06-15T11:53:13.758563Z","iopub.status.idle":"2024-06-15T11:53:13.763063Z","shell.execute_reply.started":"2024-06-15T11:53:13.758534Z","shell.execute_reply":"2024-06-15T11:53:13.762283Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"dataset = datasets.load_dataset(\"bentrevett/multi30k\")","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:53:13.765216Z","iopub.execute_input":"2024-06-15T11:53:13.765553Z","iopub.status.idle":"2024-06-15T11:53:15.914963Z","shell.execute_reply.started":"2024-06-15T11:53:13.765526Z","shell.execute_reply":"2024-06-15T11:53:15.914103Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/1.15k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"69477a82e2974fc4bd2663a9bd52ea20"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/4.60M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1bf4ea94a8be40d888c8ddee8929f75a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/164k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9991d12d2fec4e58bf6d1f5ffbd05433"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/156k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6f49553e7a2243fdb045c90de13eb0c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/29000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f7cd3844d2974f6299b2ada87356b58f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/1014 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3abb5f9d0254872aaa9cb1254499e67"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b009a72a832748629cad009c29eee3bb"}},"metadata":{}}]},{"cell_type":"code","source":"train_data, valid_data, test_data = (\n    dataset[\"train\"],\n    dataset[\"validation\"],\n    dataset[\"test\"],\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:53:15.916135Z","iopub.execute_input":"2024-06-15T11:53:15.916419Z","iopub.status.idle":"2024-06-15T11:53:15.920789Z","shell.execute_reply.started":"2024-06-15T11:53:15.916394Z","shell.execute_reply":"2024-06-15T11:53:15.919908Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"train_data[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:53:15.921864Z","iopub.execute_input":"2024-06-15T11:53:15.922146Z","iopub.status.idle":"2024-06-15T11:53:15.943553Z","shell.execute_reply.started":"2024-06-15T11:53:15.922123Z","shell.execute_reply":"2024-06-15T11:53:15.942775Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"{'en': 'Two young, White males are outside near many bushes.',\n 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.'}"},"metadata":{}}]},{"cell_type":"code","source":"en_nlp = spacy.load(\"en_core_web_sm\")\nde_nlp = spacy.load(\"de_core_news_sm\")","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:53:15.944754Z","iopub.execute_input":"2024-06-15T11:53:15.945094Z","iopub.status.idle":"2024-06-15T11:53:19.002033Z","shell.execute_reply.started":"2024-06-15T11:53:15.945059Z","shell.execute_reply":"2024-06-15T11:53:19.000743Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"string = \"zerui is a femboy\"\n\n[token.text for token in en_nlp.tokenizer(string)]","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:53:19.003267Z","iopub.execute_input":"2024-06-15T11:53:19.003564Z","iopub.status.idle":"2024-06-15T11:53:19.010823Z","shell.execute_reply.started":"2024-06-15T11:53:19.003537Z","shell.execute_reply":"2024-06-15T11:53:19.009420Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"['zerui', 'is', 'a', 'femboy']"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize_example(example, en_nlp, de_nlp, max_length, lower, sos_token, eos_token):\n    en_tokens = [token.text for token in en_nlp.tokenizer(example[\"en\"])][:max_length]\n    de_tokens = [token.text for token in de_nlp.tokenizer(example[\"de\"])][:max_length]\n    if lower:\n        en_tokens = [token.lower() for token in en_tokens]\n        de_tokens = [token.lower() for token in de_tokens]\n    en_tokens = [sos_token] + en_tokens + [eos_token]\n    de_tokens = [sos_token] + de_tokens + [eos_token]\n    return {\"en_tokens\": en_tokens, \"de_tokens\": de_tokens}","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:53:19.012143Z","iopub.execute_input":"2024-06-15T11:53:19.012520Z","iopub.status.idle":"2024-06-15T11:53:19.020894Z","shell.execute_reply.started":"2024-06-15T11:53:19.012488Z","shell.execute_reply":"2024-06-15T11:53:19.020010Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"max_length = 1_000\nlower = True\nsos_token = \"<sos>\"\neos_token = \"<eos>\"\n\nfn_kwargs = {\n    \"en_nlp\": en_nlp,\n    \"de_nlp\": de_nlp,\n    \"max_length\": max_length,\n    \"lower\": lower,\n    \"sos_token\": sos_token,\n    \"eos_token\": eos_token,\n}\n\ntrain_data = train_data.map(tokenize_example, fn_kwargs=fn_kwargs)\nvalid_data = valid_data.map(tokenize_example, fn_kwargs=fn_kwargs)\ntest_data = test_data.map(tokenize_example, fn_kwargs=fn_kwargs)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:53:19.024492Z","iopub.execute_input":"2024-06-15T11:53:19.024790Z","iopub.status.idle":"2024-06-15T11:53:31.612576Z","shell.execute_reply.started":"2024-06-15T11:53:19.024761Z","shell.execute_reply":"2024-06-15T11:53:31.611653Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/29000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f177098c1e814b628eb1910e18507b3e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1014 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"605ce3f9dad14ae4920160e426f6c99c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"241728f3f6bd46c18bf4978a5de05fd4"}},"metadata":{}}]},{"cell_type":"code","source":"train_data[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:53:31.613701Z","iopub.execute_input":"2024-06-15T11:53:31.613990Z","iopub.status.idle":"2024-06-15T11:53:31.623045Z","shell.execute_reply.started":"2024-06-15T11:53:31.613964Z","shell.execute_reply":"2024-06-15T11:53:31.622134Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"{'en': 'Two young, White males are outside near many bushes.',\n 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.',\n 'en_tokens': ['<sos>',\n  'two',\n  'young',\n  ',',\n  'white',\n  'males',\n  'are',\n  'outside',\n  'near',\n  'many',\n  'bushes',\n  '.',\n  '<eos>'],\n 'de_tokens': ['<sos>',\n  'zwei',\n  'junge',\n  'weiße',\n  'männer',\n  'sind',\n  'im',\n  'freien',\n  'in',\n  'der',\n  'nähe',\n  'vieler',\n  'büsche',\n  '.',\n  '<eos>']}"},"metadata":{}}]},{"cell_type":"code","source":"min_freq = 2\nunk_token = \"<unk>\"\npad_token = \"<pad>\"\n\nspecial_tokens = [\n    unk_token,\n    pad_token,\n    sos_token,\n    eos_token,\n]\n\nen_vocab = torchtext.vocab.build_vocab_from_iterator(\n    train_data[\"en_tokens\"],\n    min_freq=min_freq,\n    specials=special_tokens,\n)\n\nde_vocab = torchtext.vocab.build_vocab_from_iterator(\n    train_data[\"de_tokens\"],\n    min_freq=min_freq,\n    specials=special_tokens,\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:53:31.624183Z","iopub.execute_input":"2024-06-15T11:53:31.624487Z","iopub.status.idle":"2024-06-15T11:53:33.538456Z","shell.execute_reply.started":"2024-06-15T11:53:31.624463Z","shell.execute_reply":"2024-06-15T11:53:33.537610Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"en_vocab.get_itos()[:10]","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:53:33.539699Z","iopub.execute_input":"2024-06-15T11:53:33.540458Z","iopub.status.idle":"2024-06-15T11:53:33.548231Z","shell.execute_reply.started":"2024-06-15T11:53:33.540420Z","shell.execute_reply":"2024-06-15T11:53:33.547520Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"['<unk>', '<pad>', '<sos>', '<eos>', 'a', '.', 'in', 'the', 'on', 'man']"},"metadata":{}}]},{"cell_type":"code","source":"de_vocab.get_itos()[:10]","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:53:33.549833Z","iopub.execute_input":"2024-06-15T11:53:33.550122Z","iopub.status.idle":"2024-06-15T11:53:33.561055Z","shell.execute_reply.started":"2024-06-15T11:53:33.550099Z","shell.execute_reply":"2024-06-15T11:53:33.560165Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"['<unk>', '<pad>', '<sos>', '<eos>', '.', 'ein', 'einem', 'in', 'eine', ',']"},"metadata":{}}]},{"cell_type":"code","source":"en_vocab.get_stoi()[\"the\"]","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:53:33.562163Z","iopub.execute_input":"2024-06-15T11:53:33.562447Z","iopub.status.idle":"2024-06-15T11:53:33.574717Z","shell.execute_reply.started":"2024-06-15T11:53:33.562417Z","shell.execute_reply":"2024-06-15T11:53:33.573776Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"7"},"metadata":{}}]},{"cell_type":"code","source":"len(en_vocab), len(de_vocab)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:53:33.575844Z","iopub.execute_input":"2024-06-15T11:53:33.576172Z","iopub.status.idle":"2024-06-15T11:53:33.585002Z","shell.execute_reply.started":"2024-06-15T11:53:33.576142Z","shell.execute_reply":"2024-06-15T11:53:33.584198Z"},"trusted":true},"execution_count":16,"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"(5893, 7853)"},"metadata":{}}]},{"cell_type":"code","source":"assert en_vocab[unk_token] == de_vocab[unk_token]\nassert en_vocab[pad_token] == de_vocab[pad_token]\n\nunk_index = en_vocab[unk_token]\npad_index = en_vocab[pad_token]","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:53:33.586009Z","iopub.execute_input":"2024-06-15T11:53:33.586309Z","iopub.status.idle":"2024-06-15T11:53:33.593304Z","shell.execute_reply.started":"2024-06-15T11:53:33.586279Z","shell.execute_reply":"2024-06-15T11:53:33.592223Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"en_vocab.set_default_index(unk_index)\nde_vocab.set_default_index(unk_index)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:53:33.594463Z","iopub.execute_input":"2024-06-15T11:53:33.594933Z","iopub.status.idle":"2024-06-15T11:53:33.601850Z","shell.execute_reply.started":"2024-06-15T11:53:33.594903Z","shell.execute_reply":"2024-06-15T11:53:33.601082Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"def numericalize_example(example, en_vocab, de_vocab):\n    en_ids = en_vocab.lookup_indices(example[\"en_tokens\"])\n    de_ids = de_vocab.lookup_indices(example[\"de_tokens\"])\n    return {\"en_ids\": en_ids, \"de_ids\": de_ids}","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:53:33.602934Z","iopub.execute_input":"2024-06-15T11:53:33.603282Z","iopub.status.idle":"2024-06-15T11:53:33.610440Z","shell.execute_reply.started":"2024-06-15T11:53:33.603229Z","shell.execute_reply":"2024-06-15T11:53:33.609596Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"fn_kwargs = {\"en_vocab\": en_vocab, \"de_vocab\": de_vocab}\n\ntrain_data = train_data.map(numericalize_example, fn_kwargs=fn_kwargs)\nvalid_data = valid_data.map(numericalize_example, fn_kwargs=fn_kwargs)\ntest_data = test_data.map(numericalize_example, fn_kwargs=fn_kwargs)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:53:33.611545Z","iopub.execute_input":"2024-06-15T11:53:33.611802Z","iopub.status.idle":"2024-06-15T11:53:39.995258Z","shell.execute_reply.started":"2024-06-15T11:53:33.611780Z","shell.execute_reply":"2024-06-15T11:53:39.994395Z"},"trusted":true},"execution_count":20,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/29000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4133188f4e0e414fa7508687d7f5c87e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1014 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c98ce6eb3266486dbc5a1a622be5eaa6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72d0f8ee430c4aa083d1e0120333bbc2"}},"metadata":{}}]},{"cell_type":"code","source":"train_data[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:53:39.996827Z","iopub.execute_input":"2024-06-15T11:53:39.997294Z","iopub.status.idle":"2024-06-15T11:53:40.005846Z","shell.execute_reply.started":"2024-06-15T11:53:39.997246Z","shell.execute_reply":"2024-06-15T11:53:40.004813Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"{'en': 'Two young, White males are outside near many bushes.',\n 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.',\n 'en_tokens': ['<sos>',\n  'two',\n  'young',\n  ',',\n  'white',\n  'males',\n  'are',\n  'outside',\n  'near',\n  'many',\n  'bushes',\n  '.',\n  '<eos>'],\n 'de_tokens': ['<sos>',\n  'zwei',\n  'junge',\n  'weiße',\n  'männer',\n  'sind',\n  'im',\n  'freien',\n  'in',\n  'der',\n  'nähe',\n  'vieler',\n  'büsche',\n  '.',\n  '<eos>'],\n 'en_ids': [2, 16, 24, 15, 25, 778, 17, 57, 80, 202, 1312, 5, 3],\n 'de_ids': [2, 18, 26, 253, 30, 84, 20, 88, 7, 15, 110, 7647, 3171, 4, 3]}"},"metadata":{}}]},{"cell_type":"code","source":"data_type = \"torch\"\nformat_columns = [\"en_ids\", \"de_ids\"]\n\ntrain_data = train_data.with_format(\n    type=data_type, columns=format_columns, output_all_columns=True\n)\n\nvalid_data = valid_data.with_format(\n    type=data_type,\n    columns=format_columns,\n    output_all_columns=True,\n)\n\ntest_data = test_data.with_format(\n    type=data_type,\n    columns=format_columns,\n    output_all_columns=True,\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:53:40.007005Z","iopub.execute_input":"2024-06-15T11:53:40.007316Z","iopub.status.idle":"2024-06-15T11:53:40.046937Z","shell.execute_reply.started":"2024-06-15T11:53:40.007291Z","shell.execute_reply":"2024-06-15T11:53:40.046169Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"train_data[0]","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:53:40.048014Z","iopub.execute_input":"2024-06-15T11:53:40.048307Z","iopub.status.idle":"2024-06-15T11:53:40.096659Z","shell.execute_reply.started":"2024-06-15T11:53:40.048280Z","shell.execute_reply":"2024-06-15T11:53:40.095774Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"{'en_ids': tensor([   2,   16,   24,   15,   25,  778,   17,   57,   80,  202, 1312,    5,\n            3]),\n 'de_ids': tensor([   2,   18,   26,  253,   30,   84,   20,   88,    7,   15,  110, 7647,\n         3171,    4,    3]),\n 'en': 'Two young, White males are outside near many bushes.',\n 'de': 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche.',\n 'en_tokens': ['<sos>',\n  'two',\n  'young',\n  ',',\n  'white',\n  'males',\n  'are',\n  'outside',\n  'near',\n  'many',\n  'bushes',\n  '.',\n  '<eos>'],\n 'de_tokens': ['<sos>',\n  'zwei',\n  'junge',\n  'weiße',\n  'männer',\n  'sind',\n  'im',\n  'freien',\n  'in',\n  'der',\n  'nähe',\n  'vieler',\n  'büsche',\n  '.',\n  '<eos>']}"},"metadata":{}}]},{"cell_type":"code","source":"def get_collate_fn(pad_index):\n    def collate_fn(batch):\n        batch_en_ids = [example[\"en_ids\"] for example in batch]\n        batch_de_ids = [example[\"de_ids\"] for example in batch]\n        batch_en_ids = nn.utils.rnn.pad_sequence(batch_en_ids, padding_value=pad_index)\n        batch_de_ids = nn.utils.rnn.pad_sequence(batch_de_ids, padding_value=pad_index)\n        batch = {\n            \"en_ids\": batch_en_ids,\n            \"de_ids\": batch_de_ids,\n        }\n        return batch\n\n    return collate_fn","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:53:40.097640Z","iopub.execute_input":"2024-06-15T11:53:40.097874Z","iopub.status.idle":"2024-06-15T11:53:40.103706Z","shell.execute_reply.started":"2024-06-15T11:53:40.097854Z","shell.execute_reply":"2024-06-15T11:53:40.102890Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"def get_data_loader(dataset, batch_size, pad_index, shuffle=False):\n    collate_fn = get_collate_fn(pad_index)\n    data_loader = torch.utils.data.DataLoader(\n        dataset=dataset,\n        batch_size=batch_size,\n        collate_fn=collate_fn,\n        shuffle=shuffle,\n    )\n    return data_loader","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:53:40.104975Z","iopub.execute_input":"2024-06-15T11:53:40.105307Z","iopub.status.idle":"2024-06-15T11:53:40.115888Z","shell.execute_reply.started":"2024-06-15T11:53:40.105276Z","shell.execute_reply":"2024-06-15T11:53:40.115052Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"batch_size = 128\n\ntrain_data_loader = get_data_loader(train_data, batch_size, pad_index, shuffle=True)\nvalid_data_loader = get_data_loader(valid_data, batch_size, pad_index)\ntest_data_loader = get_data_loader(test_data, 1, pad_index)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:53:40.116894Z","iopub.execute_input":"2024-06-15T11:53:40.117203Z","iopub.status.idle":"2024-06-15T11:53:40.125112Z","shell.execute_reply.started":"2024-06-15T11:53:40.117180Z","shell.execute_reply":"2024-06-15T11:53:40.124389Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"import math\n\nclass PositionalEncoding(nn.Module):\n\n    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n        super().__init__()\n        self.dropout = nn.Dropout(p=dropout)\n\n        position = torch.arange(max_len).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n        pe = torch.zeros(max_len, 1, d_model)\n        pe[:, 0, 0::2] = torch.sin(position * div_term)\n        pe[:, 0, 1::2] = torch.cos(position * div_term)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        \"\"\"\n        Arguments:\n            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n        \"\"\"\n        x = x + self.pe[:x.size(0)]\n        return self.dropout(x)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T11:53:40.126282Z","iopub.execute_input":"2024-06-15T11:53:40.126827Z","iopub.status.idle":"2024-06-15T11:53:40.136060Z","shell.execute_reply.started":"2024-06-15T11:53:40.126796Z","shell.execute_reply":"2024-06-15T11:53:40.135280Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"class transformer(nn.Module):\n    def __init__(self, src_vocab_size, trg_vocab_size, embed_dim):\n        super().__init__()\n        self.src_vocab_size = src_vocab_size\n        self.trg_vocab_size = trg_vocab_size\n        self.src_embedding = nn.Embedding(src_vocab_size, embed_dim)\n        self.trg_embedding = nn.Embedding(trg_vocab_size, embed_dim)\n        self.transformer = nn.Transformer(d_model=256, nhead=8, num_encoder_layers=4, num_decoder_layers=4, dim_feedforward=1024, dropout=0.5, batch_first=False)\n        self.pos_encoding = PositionalEncoding(d_model=256)\n        self.fc = nn.Linear(embed_dim, trg_vocab_size)\n\n    def forward(self, src, trg):\n#         print(torch.max(src))\n#         assert(torch.max(src)<=self.src_vocab_size)\n        embedded_src = self.pos_encoding(self.src_embedding(src))\n#         print(torch.max(trg))\n#         assert(torch.max(trg)<=self.trg_vocab_size)\n        embedded_trg = self.pos_encoding(self.trg_embedding(trg))\n    \n        src_mask = nn.Transformer.generate_square_subsequent_mask(len(src)).to(device)\n        trg_mask = nn.Transformer.generate_square_subsequent_mask(len(trg)).to(device)\n\n        transformer_output = self.transformer(embedded_src, embedded_trg, src_mask, trg_mask)\n#         print(\"Transformer output:\", transformer_output.shape)\n#         print(\"Final output shape:\", self.fc(transformer_output).shape)\n#         assert False\n        return self.fc(transformer_output)\n","metadata":{"execution":{"iopub.status.busy":"2024-06-15T12:26:28.785199Z","iopub.execute_input":"2024-06-15T12:26:28.785594Z","iopub.status.idle":"2024-06-15T12:26:28.795266Z","shell.execute_reply.started":"2024-06-15T12:26:28.785565Z","shell.execute_reply":"2024-06-15T12:26:28.794321Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"len(en_vocab), len(de_vocab)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T12:26:28.988961Z","iopub.execute_input":"2024-06-15T12:26:28.989965Z","iopub.status.idle":"2024-06-15T12:26:28.996657Z","shell.execute_reply.started":"2024-06-15T12:26:28.989922Z","shell.execute_reply":"2024-06-15T12:26:28.995605Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"(5893, 7853)"},"metadata":{}}]},{"cell_type":"code","source":"device = \"cuda\"","metadata":{"execution":{"iopub.status.busy":"2024-06-15T12:26:29.167484Z","iopub.execute_input":"2024-06-15T12:26:29.168384Z","iopub.status.idle":"2024-06-15T12:26:29.172943Z","shell.execute_reply.started":"2024-06-15T12:26:29.168341Z","shell.execute_reply":"2024-06-15T12:26:29.171795Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"model = transformer(len(en_vocab), len(de_vocab), 256).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T12:26:29.485666Z","iopub.execute_input":"2024-06-15T12:26:29.486634Z","iopub.status.idle":"2024-06-15T12:26:29.663153Z","shell.execute_reply.started":"2024-06-15T12:26:29.486602Z","shell.execute_reply":"2024-06-15T12:26:29.662135Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\n\nprint(f\"The model has {count_parameters(model):,} trainable parameters\")","metadata":{"execution":{"iopub.status.busy":"2024-06-15T12:26:29.997896Z","iopub.execute_input":"2024-06-15T12:26:29.998268Z","iopub.status.idle":"2024-06-15T12:26:30.004621Z","shell.execute_reply.started":"2024-06-15T12:26:29.998223Z","shell.execute_reply":"2024-06-15T12:26:30.003707Z"},"trusted":true},"execution_count":56,"outputs":[{"name":"stdout","text":"The model has 12,911,021 trainable parameters\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.optim as optim\n\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriteria = nn.CrossEntropyLoss(ignore_index=pad_index)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T12:26:30.626503Z","iopub.execute_input":"2024-06-15T12:26:30.626869Z","iopub.status.idle":"2024-06-15T12:26:30.633119Z","shell.execute_reply.started":"2024-06-15T12:26:30.626839Z","shell.execute_reply":"2024-06-15T12:26:30.632105Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"def train_fn(\n    model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device\n):\n    model.train()\n    epoch_loss = 0\n    for i, batch in enumerate(data_loader):\n        src = batch[\"en_ids\"].to(device)\n        trg = batch[\"de_ids\"].to(device)\n        # src = [src length, batch size]\n        # trg = [trg length, batch size]\n        optimizer.zero_grad()\n        output = model(src, trg[:-1,])\n        # output = [trg length, batch size, trg vocab size]\n        output_dim = output.shape[-1]\n        output = output.view(-1, output_dim)\n        # output = [(trg length - 1) * batch size, trg vocab size]\n        trg = trg[1:].view(-1)\n        # trg = [(trg length - 1) * batch size]\n#         print(\"Output:\")\n#         print(output.shape)\n#         print(\"trg:\")\n#         print(trg.shape)\n        loss = criterion(output, trg)\n        loss.backward()\n#         torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n        optimizer.step()\n        epoch_loss += loss.item()\n    return epoch_loss / len(data_loader)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T12:26:31.535069Z","iopub.execute_input":"2024-06-15T12:26:31.535470Z","iopub.status.idle":"2024-06-15T12:26:31.543477Z","shell.execute_reply.started":"2024-06-15T12:26:31.535438Z","shell.execute_reply":"2024-06-15T12:26:31.542301Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"def evaluate_fn(model, data_loader, criterion, device):\n    model.eval()\n    epoch_loss = 0\n    with torch.no_grad():\n        for i, batch in enumerate(data_loader):\n            src = batch[\"en_ids\"].to(device)\n            trg = batch[\"de_ids\"].to(device)\n            # src = [src length, batch size]\n            # trg = [trg length, batch size]\n            output = model(src, trg[:-1,])  # turn off teacher forcing\n            # output = [trg length, batch size, trg vocab size]\n            output_dim = output.shape[-1]\n            output = output.view(-1, output_dim)\n            # output = [(trg length - 1) * batch size, trg vocab size]\n            trg = trg[1:].view(-1)\n            # trg = [(trg length - 1) * batch size]\n            loss = criterion(output, trg)\n            epoch_loss += loss.item()\n    return epoch_loss / len(data_loader)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T12:26:32.531630Z","iopub.execute_input":"2024-06-15T12:26:32.532472Z","iopub.status.idle":"2024-06-15T12:26:32.539374Z","shell.execute_reply.started":"2024-06-15T12:26:32.532441Z","shell.execute_reply":"2024-06-15T12:26:32.538312Z"},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\nn_epochs = 20\nclip = 1.0\nteacher_forcing_ratio = 0.5\n\nbest_valid_loss = float(\"inf\")\n\nfor epoch in tqdm(range(n_epochs)):\n    train_loss = train_fn(\n        model,\n        train_data_loader,\n        optimizer,\n        criteria,\n        clip,\n        teacher_forcing_ratio,\n        device,\n    )\n    valid_loss = evaluate_fn(\n        model,\n        valid_data_loader,\n        criteria,\n        device,\n    )\n    if valid_loss < best_valid_loss:\n        best_valid_loss = valid_loss\n        torch.save(model.state_dict(), \"tut1-model.pt\")\n    print(f\"\\tTrain Loss: {train_loss:7.3f} | Train PPL: {np.exp(train_loss):7.3f}\")\n    print(f\"\\tValid Loss: {valid_loss:7.3f} | Valid PPL: {np.exp(valid_loss):7.3f}\")","metadata":{"execution":{"iopub.status.busy":"2024-06-15T12:38:18.750214Z","iopub.execute_input":"2024-06-15T12:38:18.750609Z","iopub.status.idle":"2024-06-15T12:38:48.076395Z","shell.execute_reply.started":"2024-06-15T12:38:18.750583Z","shell.execute_reply":"2024-06-15T12:38:48.074789Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stderr","text":"  5%|▌         | 1/20 [00:19<06:15, 19.76s/it]","output_type":"stream"},{"name":"stdout","text":"\tTrain Loss:   3.390 | Train PPL:  29.653\n\tValid Loss:   3.446 | Valid PPL:  31.389\n","output_type":"stream"},{"name":"stderr","text":"  5%|▌         | 1/20 [00:28<09:03, 28.62s/it]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[74], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m best_valid_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(n_epochs)):\n\u001b[0;32m---> 10\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_data_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     valid_loss \u001b[38;5;241m=\u001b[39m evaluate_fn(\n\u001b[1;32m     20\u001b[0m         model,\n\u001b[1;32m     21\u001b[0m         valid_data_loader,\n\u001b[1;32m     22\u001b[0m         criteria,\n\u001b[1;32m     23\u001b[0m         device,\n\u001b[1;32m     24\u001b[0m     )\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m valid_loss \u001b[38;5;241m<\u001b[39m best_valid_loss:\n","Cell \u001b[0;32mIn[58], line 12\u001b[0m, in \u001b[0;36mtrain_fn\u001b[0;34m(model, data_loader, optimizer, criterion, clip, teacher_forcing_ratio, device)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# src = [src length, batch size]\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# trg = [trg length, batch size]\u001b[39;00m\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 12\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# output = [trg length, batch size, trg vocab size]\u001b[39;00m\n\u001b[1;32m     14\u001b[0m output_dim \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","Cell \u001b[0;32mIn[52], line 23\u001b[0m, in \u001b[0;36mtransformer.forward\u001b[0;34m(self, src, trg)\u001b[0m\n\u001b[1;32m     20\u001b[0m         src_mask \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mTransformer\u001b[38;5;241m.\u001b[39mgenerate_square_subsequent_mask(\u001b[38;5;28mlen\u001b[39m(src))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     21\u001b[0m         trg_mask \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mTransformer\u001b[38;5;241m.\u001b[39mgenerate_square_subsequent_mask(\u001b[38;5;28mlen\u001b[39m(trg))\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m---> 23\u001b[0m         transformer_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedded_src\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedded_trg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#         print(\"Transformer output:\", transformer_output.shape)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#         print(\"Final output shape:\", self.fc(transformer_output).shape)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m#         assert False\u001b[39;00m\n\u001b[1;32m     27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(transformer_output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:206\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, src, tgt, src_mask, tgt_mask, memory_mask, src_key_padding_mask, tgt_key_padding_mask, memory_key_padding_mask, src_is_causal, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe feature number of src and tgt must be equal to d_model\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    204\u001b[0m memory \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(src, mask\u001b[38;5;241m=\u001b[39msrc_mask, src_key_padding_mask\u001b[38;5;241m=\u001b[39msrc_key_padding_mask,\n\u001b[1;32m    205\u001b[0m                       is_causal\u001b[38;5;241m=\u001b[39msrc_is_causal)\n\u001b[0;32m--> 206\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:460\u001b[0m, in \u001b[0;36mTransformerDecoder.forward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    457\u001b[0m tgt_is_causal \u001b[38;5;241m=\u001b[39m _detect_is_causal_mask(tgt_mask, tgt_is_causal, seq_len)\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers:\n\u001b[0;32m--> 460\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmemory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    461\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmemory_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_key_padding_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mtgt_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt_is_causal\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m                 \u001b[49m\u001b[43mmemory_is_causal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmemory_is_causal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    468\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(output)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:848\u001b[0m, in \u001b[0;36mTransformerDecoderLayer.forward\u001b[0;34m(self, tgt, memory, tgt_mask, memory_mask, tgt_key_padding_mask, memory_key_padding_mask, tgt_is_causal, memory_is_causal)\u001b[0m\n\u001b[1;32m    846\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm1(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sa_block(x, tgt_mask, tgt_key_padding_mask, tgt_is_causal))\n\u001b[1;32m    847\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mha_block(x, memory, memory_mask, memory_key_padding_mask, memory_is_causal))\n\u001b[0;32m--> 848\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm3(x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ff_block\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:874\u001b[0m, in \u001b[0;36mTransformerDecoderLayer._ff_block\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_ff_block\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 874\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear2(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    875\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout3(x)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/dropout.py:58\u001b[0m, in \u001b[0;36mDropout.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 58\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:1266\u001b[0m, in \u001b[0;36mdropout\u001b[0;34m(input, p, training, inplace)\u001b[0m\n\u001b[1;32m   1264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m p \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m p \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1.0\u001b[39m:\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdropout probability has to be between 0 and 1, but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1266\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _VF\u001b[38;5;241m.\u001b[39mdropout_(\u001b[38;5;28minput\u001b[39m, p, training) \u001b[38;5;28;01mif\u001b[39;00m inplace \u001b[38;5;28;01melse\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"model.load_state_dict(torch.load(\"tut1-model.pt\"))\n\ntest_loss = evaluate_fn(model, test_data_loader, criteria, device)\n\nprint(f\"| Test Loss: {test_loss:.3f} | Test PPL: {np.exp(test_loss):7.3f} |\")","metadata":{"execution":{"iopub.status.busy":"2024-06-15T12:36:10.763078Z","iopub.execute_input":"2024-06-15T12:36:10.763782Z","iopub.status.idle":"2024-06-15T12:36:17.762417Z","shell.execute_reply.started":"2024-06-15T12:36:10.763750Z","shell.execute_reply":"2024-06-15T12:36:17.761314Z"},"trusted":true},"execution_count":61,"outputs":[{"name":"stdout","text":"| Test Loss: 3.394 | Test PPL:  29.786 |\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}