{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"NMT.ipynb","provenance":[],"collapsed_sections":[]},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Preprocessing referenced from https://pytorch.org/tutorials/beginner/torchtext_translation_tutorial.html\n\nTransformer from https://pytorch.org/docs/stable/generated/torch.nn.Transformer.html","metadata":{"id":"OzgbpoPzFR0e"}},{"cell_type":"code","source":"!pip install -U torchtext==0.8.0\n!python -m spacy download en_core_web_sm\n!python -m spacy download de_core_news_sm","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IL6UZtvR8YMY","outputId":"9437ed22-4c0b-4b0b-d3a6-c923a25e5f0f","execution":{"iopub.status.busy":"2024-06-15T10:15:09.710531Z","iopub.execute_input":"2024-06-15T10:15:09.711536Z","iopub.status.idle":"2024-06-15T10:15:57.694025Z","shell.execute_reply.started":"2024-06-15T10:15:09.711465Z","shell.execute_reply":"2024-06-15T10:15:57.692583Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[31mERROR: Could not find a version that satisfies the requirement torchtext==0.8.0 (from versions: 0.1.1, 0.2.0, 0.2.1, 0.2.3, 0.3.1, 0.4.0, 0.5.0, 0.6.0, 0.12.0, 0.13.0, 0.13.1, 0.14.0, 0.14.1, 0.15.1, 0.15.2, 0.16.0, 0.16.1, 0.16.2, 0.17.0, 0.17.1, 0.17.2, 0.18.0)\u001b[0m\u001b[31m\n\u001b[0m\u001b[31mERROR: No matching distribution found for torchtext==0.8.0\u001b[0m\u001b[31m\n\u001b[0mCollecting en-core-web-sm==3.7.1\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /opt/conda/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.4)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (69.0.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\nRequirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.1)\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_sm')\nCollecting de-core-news-sm==3.7.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from de-core-news-sm==3.7.0) (3.7.4)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.3)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.9.0)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.4)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.5.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (69.0.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.0)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.2.2)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.5)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.1.3)\nRequirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.1)\nInstalling collected packages: de-core-news-sm\nSuccessfully installed de-core-news-sm-3.7.0\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('de_core_news_sm')\n","output_type":"stream"}]},{"cell_type":"code","source":"import io\nfrom collections import Counter\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n\nimport torchtext\nfrom torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import vocab\nfrom torchtext.utils import download_from_url, extract_archive\n\nimport random\nimport numpy as np\n\nfrom tqdm import tqdm\nimport time\n\nrandom.seed(26)\nnp.random.seed(62)\ntorch.manual_seed(297)\n\ndevice = 'cuda' #torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"_csqCCbH7gJo","execution":{"iopub.status.busy":"2024-06-15T10:15:57.696927Z","iopub.execute_input":"2024-06-15T10:15:57.697454Z","iopub.status.idle":"2024-06-15T10:16:01.781365Z","shell.execute_reply.started":"2024-06-15T10:15:57.697404Z","shell.execute_reply":"2024-06-15T10:16:01.780363Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Load and preprocess data","metadata":{"id":"hdyA-tw17gJ2"}},{"cell_type":"code","source":"url_base = 'https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/raw/'\n\ntrain_urls = ('train.de.gz', 'train.en.gz')\nval_urls = ('val.de.gz', 'val.en.gz')\ntest_urls = ('test_2016_flickr.de.gz', 'test_2016_flickr.en.gz')\n\ntrain_files = [extract_archive(download_from_url(url_base + url))[0] for url in train_urls]\nval_files = [extract_archive(download_from_url(url_base + url))[0] for url in val_urls]\ntest_files = [extract_archive(download_from_url(url_base + url))[0] for url in test_urls]","metadata":{"id":"-GE13vKt7gJ3","execution":{"iopub.status.busy":"2024-06-15T10:16:01.782860Z","iopub.execute_input":"2024-06-15T10:16:01.783563Z","iopub.status.idle":"2024-06-15T10:16:04.692211Z","shell.execute_reply.started":"2024-06-15T10:16:01.783511Z","shell.execute_reply":"2024-06-15T10:16:04.691021Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"100%|██████████| 637k/637k [00:00<00:00, 3.95MB/s]\n100%|██████████| 569k/569k [00:00<00:00, 3.43MB/s]\n100%|██████████| 24.7k/24.7k [00:00<00:00, 5.11MB/s]\n100%|██████████| 21.6k/21.6k [00:00<00:00, 6.96MB/s]\n100%|██████████| 22.9k/22.9k [00:00<00:00, 6.29MB/s]\n100%|██████████| 21.1k/21.1k [00:00<00:00, 5.57MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"de_tokenizer = get_tokenizer('spacy', language='de_core_news_sm')\nen_tokenizer = get_tokenizer('spacy', language='en_core_web_sm')\n\ndef build_vocab(file, tokenizer):\n    counter = Counter()\n    with io.open(file, encoding='utf8') as f:\n        for s in f:\n            counter.update(tokenizer(s))\n#     voc = vocab(counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n    \n    return vocab(counter, specials=['<unk>', '<pad>', '<bos>', '<eos>'])\n\nde_vocab = build_vocab(train_files[0], de_tokenizer)\nen_vocab = build_vocab(train_files[1], en_tokenizer)","metadata":{"id":"lRm9nqkD7gJ4","execution":{"iopub.status.busy":"2024-06-15T10:16:04.694864Z","iopub.execute_input":"2024-06-15T10:16:04.695230Z","iopub.status.idle":"2024-06-15T10:16:15.440239Z","shell.execute_reply.started":"2024-06-15T10:16:04.695199Z","shell.execute_reply":"2024-06-15T10:16:15.439176Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"unk_token = \"<unk>\"\npad_token = \"<pad>\"\nunk_index = en_vocab[unk_token]\npad_index = en_vocab[pad_token]","metadata":{"execution":{"iopub.status.busy":"2024-06-15T10:16:15.441622Z","iopub.execute_input":"2024-06-15T10:16:15.442352Z","iopub.status.idle":"2024-06-15T10:16:15.449651Z","shell.execute_reply.started":"2024-06-15T10:16:15.442313Z","shell.execute_reply":"2024-06-15T10:16:15.448194Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"en_vocab.set_default_index(unk_index)\nde_vocab.set_default_index(unk_index)","metadata":{"execution":{"iopub.status.busy":"2024-06-15T10:16:15.451013Z","iopub.execute_input":"2024-06-15T10:16:15.451390Z","iopub.status.idle":"2024-06-15T10:16:15.461631Z","shell.execute_reply.started":"2024-06-15T10:16:15.451354Z","shell.execute_reply":"2024-06-15T10:16:15.460336Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"def transform_raw(vocab, tokenizer, raw_file):\n    string_iter = iter(io.open(raw_file, encoding='utf8'))\n    data = [torch.tensor([vocab[w] for w in tokenizer(s)]) for s in string_iter]\n    return data","metadata":{"id":"qcY1E9iU7gJ5","execution":{"iopub.status.busy":"2024-06-15T10:16:15.463089Z","iopub.execute_input":"2024-06-15T10:16:15.463440Z","iopub.status.idle":"2024-06-15T10:16:15.473645Z","shell.execute_reply.started":"2024-06-15T10:16:15.463407Z","shell.execute_reply":"2024-06-15T10:16:15.472532Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"de_train = transform_raw(de_vocab, de_tokenizer, train_files[0])\nen_train = transform_raw(en_vocab, en_tokenizer, train_files[1])\ntrain = list(zip(de_train, en_train))\n\nde_val = transform_raw(de_vocab, de_tokenizer, val_files[0])\nen_val = transform_raw(en_vocab, en_tokenizer, val_files[1])\nval = list(zip(de_val, en_val))\n\nde_test = transform_raw(de_vocab, de_tokenizer, test_files[0])\nen_test = transform_raw(en_vocab, en_tokenizer, test_files[1])\ntest = list(zip(de_test, en_test))","metadata":{"id":"g64pir857gJ6","execution":{"iopub.status.busy":"2024-06-15T10:16:15.474917Z","iopub.execute_input":"2024-06-15T10:16:15.475276Z","iopub.status.idle":"2024-06-15T10:16:21.019443Z","shell.execute_reply.started":"2024-06-15T10:16:15.475248Z","shell.execute_reply":"2024-06-15T10:16:21.018347Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"# Prepare Data Loaders","metadata":{"id":"OQ0kg9w57gJ7"}},{"cell_type":"code","source":"from torch.nn.utils.rnn import pad_sequence\nfrom torch.utils.data import DataLoader\n\nBATCH_SIZE = 128\nPAD_IDX = de_vocab['<pad>']\nBOS_IDX = de_vocab['<bos>']\nEOS_IDX = en_vocab['<eos>']\n\ndef preprocess_batch(batch):\n    de_batch, en_batch = [], []\n    for de_sentence, en_sentence in batch:\n        de_batch.append(torch.cat([\n            torch.tensor([BOS_IDX]), de_sentence, torch.tensor([EOS_IDX])\n            # de_sentence, torch.tensor([EOS_IDX])\n        ], dim=0))\n        en_batch.append(torch.cat([\n            torch.tensor([BOS_IDX]), en_sentence, torch.tensor([EOS_IDX])\n        ], dim=0))\n    de_batch = pad_sequence(de_batch, padding_value=PAD_IDX)\n    en_batch = pad_sequence(en_batch, padding_value=PAD_IDX)\n    return (de_batch, en_batch)\n\ntrain_iter = DataLoader(train, batch_size=BATCH_SIZE, shuffle=True, collate_fn=preprocess_batch)\nval_iter = DataLoader(val, batch_size=BATCH_SIZE, shuffle=False, collate_fn=preprocess_batch)\ntest_iter = DataLoader(test, batch_size=1, shuffle=False, collate_fn=preprocess_batch)","metadata":{"id":"IjUtWJyk7gJ7","execution":{"iopub.status.busy":"2024-06-15T10:16:21.021157Z","iopub.execute_input":"2024-06-15T10:16:21.021616Z","iopub.status.idle":"2024-06-15T10:16:21.033510Z","shell.execute_reply.started":"2024-06-15T10:16:21.021583Z","shell.execute_reply":"2024-06-15T10:16:21.032337Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"# Define the Network","metadata":{"id":"XDcXBX3_7gJ8"}},{"cell_type":"code","source":"device=\"cpu\"\n\nEN_VOCAB_SIZE = len(en_vocab)\nDE_VOCAB_SIZE = len(de_vocab)\nD_MODEL = 128\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        \n        self.de_embed = nn.Embedding(DE_VOCAB_SIZE, D_MODEL)\n        self.en_embed = nn.Embedding(EN_VOCAB_SIZE, D_MODEL)\n        self.transformer = nn.Transformer(d_model=D_MODEL, \n            num_encoder_layers=2, num_decoder_layers=2, \n            dropout=0.5, dim_feedforward=2048)\n        self.fc1 = nn.Linear(D_MODEL, EN_VOCAB_SIZE)\n    \n    def forward(self, inputs, targets):\n        x = self.de_embed(inputs)\n        y = self.en_embed(targets)\n        tgt_mask = torch.triu(torch.ones(targets.size(0), targets.size(0)), diagonal=1).bool().to(device)\n        out = self.transformer(x, y, tgt_mask=tgt_mask)\n        out = self.fc1(out.permute(1, 0, 2)) # (batch, sequence, feature)\n        return out.permute(1, 0, 2).reshape(-1, EN_VOCAB_SIZE) # (sequence, batch, feature)\n\nnet = Net().to(device)\n\ncriterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\noptimizer = optim.Adam(net.parameters())","metadata":{"id":"WhlAzrp27gJ9","execution":{"iopub.status.busy":"2024-06-15T10:16:21.037040Z","iopub.execute_input":"2024-06-15T10:16:21.037428Z","iopub.status.idle":"2024-06-15T10:16:22.167984Z","shell.execute_reply.started":"2024-06-15T10:16:21.037395Z","shell.execute_reply":"2024-06-15T10:16:22.166958Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"def to_sentence(ts):\n    \"\"\" Convert list of word-index to a sentence \"\"\"\n    return ' '.join([en_vocab.get_itos()[x] for x in ts.squeeze() if x != PAD_IDX])\n\nfrom torchtext.data.metrics import bleu_score\n\ndef eval_model(max_output_len=50, beam_search=False, beam_num=3):\n    \"\"\" Run the NMT model on the validation set, return the average bleu-score \"\"\"\n    losses = 0.\n    scores = 0.\n    cnt = 0\n    net.eval()\n    for inputs_batch, targets_batch in val_iter:\n        for i in range(inputs_batch.size(1)):\n            inputs, targets = inputs_batch[:,i:i+1], targets_batch[:,i:i+1]\n            my_targets = targets[:1]\n            if beam_search:\n                pass\n            else:\n                while len(my_targets) < max_output_len and my_targets[-1] != en_vocab['<eos>']:\n                    pred = net(inputs.to(device), my_targets.to(device))\n                    my_targets = torch.cat((\n                        my_targets, \n                        pred[-1,].argmax().unsqueeze(dim=0).unsqueeze(dim=0).to('cpu')\n                    ))\n\n            target_sentence = to_sentence(targets[1:-1])\n            pred_sentence = to_sentence(my_targets[1:-1])\n            score = bleu_score([pred_sentence.split()], [[target_sentence.split()]])\n            scores += score\n            cnt += 1\n    \n    return scores/cnt\n\ndef test_model():\n    \"\"\" Run the NMT model on the test set, show some example translation and average bleu-score \"\"\"\n    losses = 0.\n    scores = 0.\n    cnt = 0\n    net.eval()\n    for i, (inputs, targets) in enumerate(test_iter):\n        my_targets = targets[:1]\n        while len(my_targets) < 50 and my_targets[-1] != en_vocab['<eos>']:\n            pred = net(inputs.to(device), my_targets.to(device))\n            my_targets = torch.cat((\n                my_targets, \n                pred[-1,].argmax().unsqueeze(dim=0).unsqueeze(dim=0).to('cpu')\n            ))\n\n        target_sentence = to_sentence(targets[1:-1])\n        pred_sentence = to_sentence(my_targets[1:-1])\n        score = bleu_score([pred_sentence.split()], [[target_sentence.split()]])\n        scores += score\n        cnt += 1\n        if i < 10:\n            print(f'Bleu score: {score:.4f}')\n            print(f'Truth: {target_sentence} Pred: {pred_sentence}')\n    \n    print(f'Average Bleu score: {scores/cnt:.4f}')\n\ndef evaluate():\n    \"\"\" Fast (not accurate) evaluation on validation set, return average loss \"\"\"\n    losses = 0.\n\n    net.eval()\n    for i, (inputs, targets) in enumerate(val_iter):\n        pred = net(inputs.to(device), targets[:-1,].to(device))\n\n        loss = criterion(pred.to('cpu'), targets[1:,].view(-1))\n        losses += loss.detach().item()\n    \n    return losses / (i+1)\n","metadata":{"id":"29wY0lZ67gJ-","execution":{"iopub.status.busy":"2024-06-15T11:42:27.577913Z","iopub.execute_input":"2024-06-15T11:42:27.578732Z","iopub.status.idle":"2024-06-15T11:42:27.599771Z","shell.execute_reply.started":"2024-06-15T11:42:27.578693Z","shell.execute_reply":"2024-06-15T11:42:27.598365Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def train_network(epoch_range):\n    net.train()\n    for epoch in epoch_range:\n        losses = 0.\n        with tqdm(total=len(train_iter)) as pbar:\n            for i, (inputs, targets) in enumerate(train_iter):\n                optimizer.zero_grad()\n#                 print(targets[:-1,].shape)\n#                 print(targets.shape)\n                pred = net(inputs.to(device), targets[:-1,].to(device))\n#                 print(pred.shape)\n#                 print(targets[1:,].view(-1).shape)\n#                 print(targets[0])\n                loss = criterion(pred.to('cpu'), targets[1:,].view(-1))\n                loss.backward()\n                optimizer.step()\n                \n                losses += loss.detach().item()\n                pbar.set_description(f'training loss: {losses/(i+1):.4f}')\n                pbar.update(1)\n#                 1/0\n\n        print(f'Epoch {epoch:2}, train loss: {(losses/(i+1)):.6f}, val loss: {evaluate():.6f}, val bleu-score: {eval_model():.4f}')\n\ntrain_network(range(1, 11))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kYWRpk1JiFD5","outputId":"73928cb4-5514-40f1-d3fd-a50d2e83a671","execution":{"iopub.status.busy":"2024-06-15T11:41:54.609897Z","iopub.status.idle":"2024-06-15T11:41:54.610268Z","shell.execute_reply.started":"2024-06-15T11:41:54.610088Z","shell.execute_reply":"2024-06-15T11:41:54.610103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_network(range(11, 16))","metadata":{"id":"1OGh21fLelrQ","execution":{"iopub.status.busy":"2024-06-15T11:41:54.611699Z","iopub.status.idle":"2024-06-15T11:41:54.612065Z","shell.execute_reply.started":"2024-06-15T11:41:54.611885Z","shell.execute_reply":"2024-06-15T11:41:54.611900Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_model()","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bG6e3LeFnOMP","outputId":"52633cfa-7899-4405-c6e5-61aed0a2a66e","execution":{"iopub.status.busy":"2024-06-15T11:42:32.776308Z","iopub.execute_input":"2024-06-15T11:42:32.777148Z","iopub.status.idle":"2024-06-15T11:42:59.208382Z","shell.execute_reply.started":"2024-06-15T11:42:32.777106Z","shell.execute_reply":"2024-06-15T11:42:59.206648Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"Bleu score: 0.0000\nTruth: A man in an orange hat starring at something . \n Pred: A man with a red hat is holding a bicycle with a bicycle . \n\nBleu score: 0.0000\nTruth: A Boston Terrier is running on lush green grass in front of a white fence . \n Pred: A person in a white dog is jumping over a field . \n\nBleu score: 0.0000\nTruth: A girl in karate uniform breaking a stick with a front kick . \n Pred: A girl in a black shirt is holding a girl in a red shirt is holding a red shirt is holding a tree . \n\nBleu score: 0.1457\nTruth: Five people wearing winter jackets and helmets stand in the snow , with <unk> in the background . \n Pred: Three men in blue and white shirts are standing in the background . \n\nBleu score: 0.0000\nTruth: People are fixing the roof of a house . \n Pred: A person is jumping over a building . \n\nBleu score: 0.0000\nTruth: A man in light colored clothing photographs a group of men wearing dark suits and hats standing around a woman dressed in a <unk> gown . \n Pred: A man in a black shirt and a woman are standing in a woman in a table . \n\nBleu score: 0.0883\nTruth: A group of people standing in front of an igloo . \n Pred: A group of people in front of a group of a group of a group of a group of a group of a group of a group of a group of a group of a group of people . \n\nBleu score: 0.0000\nTruth: A boy in a red uniform is attempting to avoid getting out at home plate , while the catcher in the blue uniform is attempting to catch him . \n Pred: A young boy in a blue and white shirt is jumping into the air to catch a building . \n\nBleu score: 0.0000\nTruth: A guy works on a building . \n Pred: A man is riding a bike on a street . \n\nBleu score: 0.1545\nTruth: A man in a vest is sitting in a chair and holding magazines . \n Pred: A man in a black shirt and a black shirt and a man is sitting on a bench in a bench . \n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[35], line 51\u001b[0m, in \u001b[0;36mtest_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m     pred \u001b[38;5;241m=\u001b[39m net(inputs\u001b[38;5;241m.\u001b[39mto(device), my_targets\u001b[38;5;241m.\u001b[39mto(device))\n\u001b[1;32m     46\u001b[0m     my_targets \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((\n\u001b[1;32m     47\u001b[0m         my_targets, \n\u001b[1;32m     48\u001b[0m         pred[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,]\u001b[38;5;241m.\u001b[39margmax()\u001b[38;5;241m.\u001b[39munsqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     49\u001b[0m     ))\n\u001b[0;32m---> 51\u001b[0m target_sentence \u001b[38;5;241m=\u001b[39m \u001b[43mto_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m pred_sentence \u001b[38;5;241m=\u001b[39m to_sentence(my_targets[\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m     53\u001b[0m score \u001b[38;5;241m=\u001b[39m bleu_score([pred_sentence\u001b[38;5;241m.\u001b[39msplit()], [[target_sentence\u001b[38;5;241m.\u001b[39msplit()]])\n","Cell \u001b[0;32mIn[35], line 3\u001b[0m, in \u001b[0;36mto_sentence\u001b[0;34m(ts)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_sentence\u001b[39m(ts):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Convert list of word-index to a sentence \"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([en_vocab\u001b[38;5;241m.\u001b[39mget_itos()[x] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m ts\u001b[38;5;241m.\u001b[39msqueeze() \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m!=\u001b[39m PAD_IDX])\n","Cell \u001b[0;32mIn[35], line 3\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mto_sentence\u001b[39m(ts):\n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" Convert list of word-index to a sentence \"\"\"\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([\u001b[43men_vocab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_itos\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[x] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m ts\u001b[38;5;241m.\u001b[39msqueeze() \u001b[38;5;28;01mif\u001b[39;00m x \u001b[38;5;241m!=\u001b[39m PAD_IDX])\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchtext/vocab/vocab.py:158\u001b[0m, in \u001b[0;36mVocab.get_itos\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mexport\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_itos\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    154\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m    Returns:\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m        List mapping indices to tokens.\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_itos\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{"id":"ouh7LS7CjAVG"},"execution_count":null,"outputs":[]}]}