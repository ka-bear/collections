{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1903404,"sourceType":"datasetVersion","datasetId":1134553}],"dockerImageVersionId":30056,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n> To build a neural machine translation model to translate Russian text to English. A Seq2Seq model is a model that takes a sequence of items (words, letters, time series, etc) and outputs another sequence of items.The encoder captures the context of the input sequence in the form of a hidden state vector and sends it to the decoder, which then produces the output sequence.\n\n> The dataset is taken from the tatoeba Project.\n\n> This notebook implements GRU's with Attention mechanism in a Encoder-Decoder architecture on Russian-English sentence pairs. Framework used is Pytorch/Torchtext and Spacy.\n\n## The entire code can also be found on [github](https://github.com/jelifysh/Seq2seq-Machine-Translation-with-Attention)","metadata":{}},{"cell_type":"markdown","source":"# *Please upvote the kernel if you find it insightful*","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries","metadata":{"id":"mYhliw_ep7N8"}},{"cell_type":"code","source":"import re\nimport time\nimport math\nimport random\n\nimport numpy as np\nimport pandas as pd\nimport spacy\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchtext import data\n\nfrom tqdm import notebook\npd.set_option('display.max_colwidth', 200)\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"id":"_tuTL_xFX9KH","executionInfo":{"status":"ok","timestamp":1597608640549,"user_tz":-330,"elapsed":1843,"user":{"displayName":"Prateek Joshi","photoUrl":"","userId":"14172408186104425556"}},"execution":{"iopub.status.busy":"2024-05-19T07:56:33.109446Z","iopub.execute_input":"2024-05-19T07:56:33.109854Z","iopub.status.idle":"2024-05-19T07:56:36.940593Z","shell.execute_reply.started":"2024-05-19T07:56:33.109766Z","shell.execute_reply":"2024-05-19T07:56:36.939623Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# dependency for spaCy Russian tokenizer\n!pip install pymorphy2","metadata":{"id":"o94Lg0TCZS2j","executionInfo":{"status":"ok","timestamp":1597608657853,"user_tz":-330,"elapsed":5562,"user":{"displayName":"Prateek Joshi","photoUrl":"","userId":"14172408186104425556"}},"outputId":"e23d5759-7bc6-4964-c09c-53d5114a71d1","execution":{"iopub.status.busy":"2024-05-19T07:56:36.942721Z","iopub.execute_input":"2024-05-19T07:56:36.943093Z","iopub.status.idle":"2024-05-19T07:56:47.665619Z","shell.execute_reply.started":"2024-05-19T07:56:36.943055Z","shell.execute_reply":"2024-05-19T07:56:47.664671Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Collecting pymorphy2\n  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n\u001b[K     |████████████████████████████████| 55 kB 1.8 MB/s eta 0:00:011\n\u001b[?25hCollecting docopt>=0.6\n  Downloading docopt-0.6.2.tar.gz (25 kB)\nCollecting dawg-python>=0.7.1\n  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\nCollecting pymorphy2-dicts-ru<3.0,>=2.4\n  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n\u001b[K     |████████████████████████████████| 8.2 MB 6.1 MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: docopt\n  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=0b0474f6bd92e2a26afe63851edee4134a0d6ba5faf7d2152eb18f819e9e2fc3\n  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\nSuccessfully built docopt\nInstalling collected packages: pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2\nSuccessfully installed dawg-python-0.7.2 docopt-0.6.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n\u001b[33mWARNING: You are using pip version 21.0; however, version 24.0 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"# check GPU availability\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"id":"Yq5n52WdZDcG","executionInfo":{"status":"ok","timestamp":1597608641347,"user_tz":-330,"elapsed":971,"user":{"displayName":"Prateek Joshi","photoUrl":"","userId":"14172408186104425556"}},"outputId":"976c0e74-e282-42eb-d254-d6ab96f6876f","execution":{"iopub.status.busy":"2024-05-19T07:56:47.667743Z","iopub.execute_input":"2024-05-19T07:56:47.668144Z","iopub.status.idle":"2024-05-19T07:56:47.726554Z","shell.execute_reply.started":"2024-05-19T07:56:47.668099Z","shell.execute_reply":"2024-05-19T07:56:47.725793Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Create Field Objects","metadata":{"id":"h-n-voh4qVqr"}},{"cell_type":"code","source":"# import Russian spacy model to tokenize Russian text\nfrom spacy.lang.ru import Russian","metadata":{"id":"WHoAFbeGZO9f","executionInfo":{"status":"ok","timestamp":1597608653659,"user_tz":-330,"elapsed":2035,"user":{"displayName":"Prateek Joshi","photoUrl":"","userId":"14172408186104425556"}},"execution":{"iopub.status.busy":"2024-05-19T07:56:47.728013Z","iopub.execute_input":"2024-05-19T07:56:47.728304Z","iopub.status.idle":"2024-05-19T07:56:47.744084Z","shell.execute_reply.started":"2024-05-19T07:56:47.728272Z","shell.execute_reply":"2024-05-19T07:56:47.743129Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# spacy object for Russian\nnlp_ru = Russian()\n\n# spacy object for English\nnlp_en = spacy.load(\"en_core_web_sm\", disable = [\"parser\", \"tagger\", \"ner\"])","metadata":{"id":"0EjIFuhyZUFX","executionInfo":{"status":"ok","timestamp":1597608658735,"user_tz":-330,"elapsed":1830,"user":{"displayName":"Prateek Joshi","photoUrl":"","userId":"14172408186104425556"}},"execution":{"iopub.status.busy":"2024-05-19T07:56:47.747120Z","iopub.execute_input":"2024-05-19T07:56:47.747391Z","iopub.status.idle":"2024-05-19T07:56:49.165739Z","shell.execute_reply.started":"2024-05-19T07:56:47.747364Z","shell.execute_reply":"2024-05-19T07:56:49.165026Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"## functions to perform tokenization\n\n# tokenizes Russian text from a string into a list of tokens\ndef tokenize_ru(text):\n  return [tok.text for tok in nlp_ru.tokenizer(text)]\n\n# tokenizes English text from a string into a list of tokens\ndef tokenize_en(text):\n  return [tok.text for tok in nlp_en.tokenizer(text)]","metadata":{"id":"xku6rYQ5ZVqg","executionInfo":{"status":"ok","timestamp":1597608659424,"user_tz":-330,"elapsed":1833,"user":{"displayName":"Prateek Joshi","photoUrl":"","userId":"14172408186104425556"}},"execution":{"iopub.status.busy":"2024-05-19T07:56:49.168767Z","iopub.execute_input":"2024-05-19T07:56:49.169050Z","iopub.status.idle":"2024-05-19T07:56:49.178315Z","shell.execute_reply.started":"2024-05-19T07:56:49.169022Z","shell.execute_reply":"2024-05-19T07:56:49.177476Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"## Create Field objects\n\n# Field object for Russian\nSRC = data.Field(tokenize = tokenize_ru, \n                 include_lengths = True, \n                 lower = True)\n\n# Field object for English\nTRG = data.Field(tokenize = tokenize_en, \n                 init_token = '<sos>', # \"start\" token\n                 eos_token = '<eos>', # \"\" token\n                 include_lengths = True, \n                 lower = True)\n\nfields = [('rus', SRC), ('eng', TRG)]","metadata":{"id":"N3kbwvXBZciJ","executionInfo":{"status":"ok","timestamp":1597608667507,"user_tz":-330,"elapsed":1445,"user":{"displayName":"Prateek Joshi","photoUrl":"","userId":"14172408186104425556"}},"execution":{"iopub.status.busy":"2024-05-19T07:56:49.179277Z","iopub.execute_input":"2024-05-19T07:56:49.179560Z","iopub.status.idle":"2024-05-19T07:56:49.189432Z","shell.execute_reply.started":"2024-05-19T07:56:49.179534Z","shell.execute_reply":"2024-05-19T07:56:49.188263Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Data Preparation\n\n**Build Vocabulary**","metadata":{"id":"BurPxISEqp8W"}},{"cell_type":"code","source":"# importing data from csv\nnmt_data = data.TabularDataset(path=\"../input/englishrussiansentencepairs/data/train.csv\", format='csv', fields=fields)","metadata":{"id":"Lp8cztUfb1ia","executionInfo":{"status":"ok","timestamp":1597608721860,"user_tz":-330,"elapsed":14894,"user":{"displayName":"Prateek Joshi","photoUrl":"","userId":"14172408186104425556"}},"execution":{"iopub.status.busy":"2024-05-19T07:56:49.190852Z","iopub.execute_input":"2024-05-19T07:56:49.191208Z","iopub.status.idle":"2024-05-19T07:57:07.942450Z","shell.execute_reply.started":"2024-05-19T07:56:49.191168Z","shell.execute_reply":"2024-05-19T07:57:07.941750Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# build vocabulary for Russian sequences\nSRC.build_vocab(nmt_data, max_size=4000)\n\n# build vocabulary for English sequences\nTRG.build_vocab(nmt_data, max_size=4000)","metadata":{"id":"aN8F4PXBb-I2","executionInfo":{"status":"ok","timestamp":1597608722672,"user_tz":-330,"elapsed":2580,"user":{"displayName":"Prateek Joshi","photoUrl":"","userId":"14172408186104425556"}},"execution":{"iopub.status.busy":"2024-05-19T07:57:07.943551Z","iopub.execute_input":"2024-05-19T07:57:07.943851Z","iopub.status.idle":"2024-05-19T07:57:09.270755Z","shell.execute_reply.started":"2024-05-19T07:57:07.943822Z","shell.execute_reply":"2024-05-19T07:57:09.269983Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# check size of vocabulary\nlen(SRC.vocab), len(TRG.vocab)","metadata":{"id":"fjcIdKfRrCLa","executionInfo":{"status":"ok","timestamp":1597608722676,"user_tz":-330,"elapsed":2245,"user":{"displayName":"Prateek Joshi","photoUrl":"","userId":"14172408186104425556"}},"outputId":"8a512f7f-96c4-408f-b3be-3ad17ca204c9","execution":{"iopub.status.busy":"2024-05-19T07:57:09.272160Z","iopub.execute_input":"2024-05-19T07:57:09.272537Z","iopub.status.idle":"2024-05-19T07:57:09.280151Z","shell.execute_reply.started":"2024-05-19T07:57:09.272497Z","shell.execute_reply":"2024-05-19T07:57:09.279302Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"(4002, 4004)"},"metadata":{}}]},{"cell_type":"markdown","source":"# Create Dataloaders","metadata":{"id":"uk_grHZxrJOE"}},{"cell_type":"code","source":"# Split our dialogue data into training, validation, and test sets\ntrain_data, val_data = nmt_data.split(split_ratio=0.8)","metadata":{"id":"242vRepjcS4T","executionInfo":{"status":"ok","timestamp":1597608727361,"user_tz":-330,"elapsed":1508,"user":{"displayName":"Prateek Joshi","photoUrl":"","userId":"14172408186104425556"}},"execution":{"iopub.status.busy":"2024-05-19T07:57:09.281333Z","iopub.execute_input":"2024-05-19T07:57:09.281639Z","iopub.status.idle":"2024-05-19T07:57:09.601942Z","shell.execute_reply.started":"2024-05-19T07:57:09.281600Z","shell.execute_reply":"2024-05-19T07:57:09.601065Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Create a set of iterators for each split\ntrain_iterator, valid_iterator = data.BucketIterator.splits(\n    (train_data, val_data), \n    batch_size = 64, \n    sort_within_batch = True, \n    sort_key = lambda x:len(x.rus),\n    device = device)","metadata":{"id":"fnHMNU_ScWrO","executionInfo":{"status":"ok","timestamp":1597608727363,"user_tz":-330,"elapsed":1143,"user":{"displayName":"Prateek Joshi","photoUrl":"","userId":"14172408186104425556"}},"execution":{"iopub.status.busy":"2024-05-19T07:57:09.603229Z","iopub.execute_input":"2024-05-19T07:57:09.603516Z","iopub.status.idle":"2024-05-19T07:57:09.608716Z","shell.execute_reply.started":"2024-05-19T07:57:09.603485Z","shell.execute_reply":"2024-05-19T07:57:09.607621Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Define Model Architecture","metadata":{"id":"cFZDfZwGrSqQ"}},{"cell_type":"markdown","source":"# Encoder Architecture","metadata":{}},{"cell_type":"code","source":"class Encoder(nn.Module):\n  \n  def __init__(self, hidden_size, embedding_size, num_layers=2, dropout=0.3):\n    \n    super(Encoder, self).__init__()\n    \n    # Basic network params\n    self.hidden_size = hidden_size\n    self.embedding_size = embedding_size\n    self.num_layers = num_layers\n    self.dropout = dropout\n    \n    # Embedding layer that will be shared with Decoder\n    self.embedding = nn.Embedding(len(SRC.vocab), embedding_size)\n    # GRU layer\n    self.gru = nn.GRU(embedding_size, hidden_size,\n                      num_layers=num_layers,\n                      dropout=dropout)\n      \n  def forward(self, input_sequence):\n      \n    # Convert input_sequence to word embeddings\n    embedded = self.embedding(input_sequence)\n            \n    outputs, hidden = self.gru(embedded)\n    \n    # The ouput of a GRU has shape -> (seq_len, batch, hidden_size)\n    return outputs, hidden","metadata":{"id":"mQc_6hSdcfel","executionInfo":{"status":"ok","timestamp":1597608675229,"user_tz":-330,"elapsed":2039,"user":{"displayName":"Prateek Joshi","photoUrl":"","userId":"14172408186104425556"}},"execution":{"iopub.status.busy":"2024-05-19T07:57:09.610017Z","iopub.execute_input":"2024-05-19T07:57:09.610302Z","iopub.status.idle":"2024-05-19T07:57:09.619383Z","shell.execute_reply.started":"2024-05-19T07:57:09.610269Z","shell.execute_reply":"2024-05-19T07:57:09.618557Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"# Attention Mechanism","metadata":{"id":"YvuX2zbbXL6Y"}},{"cell_type":"code","source":"class Attention(nn.Module):\n  def __init__(self, hidden_size):\n    super(Attention, self).__init__()        \n    self.hidden_size = hidden_size\n      \n    \n  def dot_score(self, hidden_state, encoder_states):\n    return torch.sum(hidden_state * encoder_states, dim=2)\n  \n          \n  def forward(self, hidden, encoder_outputs, mask):\n      \n    attn_scores = self.dot_score(hidden, encoder_outputs)\n    \n    # Transpose max_length and batch_size dimensions\n    attn_scores = attn_scores.t()\n    \n    # Apply mask so network does not attend <pad> tokens        \n    attn_scores = attn_scores.masked_fill(mask == 0, -1e5)\n    \n    # Return softmax over attention scores      \n    return F.softmax(attn_scores, dim=1).unsqueeze(1)","metadata":{"id":"VdCbw3Q6e7cI","executionInfo":{"status":"ok","timestamp":1597608676951,"user_tz":-330,"elapsed":914,"user":{"displayName":"Prateek Joshi","photoUrl":"","userId":"14172408186104425556"}},"execution":{"iopub.status.busy":"2024-05-19T07:57:09.620850Z","iopub.execute_input":"2024-05-19T07:57:09.621199Z","iopub.status.idle":"2024-05-19T07:57:09.628411Z","shell.execute_reply.started":"2024-05-19T07:57:09.621164Z","shell.execute_reply":"2024-05-19T07:57:09.627675Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"markdown","source":"# Decoder Architecture","metadata":{"id":"rBwK8bWFXV9Z"}},{"cell_type":"code","source":"class Decoder(nn.Module):\n  def __init__(self, embedding_size, hidden_size, output_size, n_layers=2, dropout=0.3):\n      \n    super(Decoder, self).__init__()\n    \n    # Basic network params\n    self.hidden_size = hidden_size\n    self.output_size = output_size\n    self.n_layers = n_layers\n    self.dropout = dropout\n    self.embedding = nn.Embedding(output_size, embedding_size)\n            \n    self.gru = nn.GRU(embedding_size, hidden_size, n_layers, \n                      dropout=dropout)\n    \n    self.concat = nn.Linear(hidden_size * 2, hidden_size)\n    self.out = nn.Linear(hidden_size, output_size)\n    self.attn = Attention(hidden_size)\n      \n  def forward(self, current_token, hidden_state, encoder_outputs, mask):\n    \n    # convert current_token to word_embedding\n    embedded = self.embedding(current_token)\n    \n    # Pass through GRU\n    gru_output, hidden_state = self.gru(embedded, hidden_state)\n    \n    # Calculate attention weights\n    attention_weights = self.attn(gru_output, encoder_outputs, mask)\n    \n    # Calculate context vector (weigthed average)\n    context = attention_weights.bmm(encoder_outputs.transpose(0, 1))\n    \n    # Concatenate  context vector and GRU output\n    gru_output = gru_output.squeeze(0)\n    context = context.squeeze(1)\n    concat_input = torch.cat((gru_output, context), 1)\n    concat_output = torch.tanh(self.concat(concat_input))\n    \n    # Pass concat_output to final output layer\n    output = self.out(concat_output)\n    \n    # Return output and final hidden state\n    return output, hidden_state","metadata":{"id":"ws1f7ONofEd9","executionInfo":{"status":"ok","timestamp":1597608680710,"user_tz":-330,"elapsed":1458,"user":{"displayName":"Prateek Joshi","photoUrl":"","userId":"14172408186104425556"}},"execution":{"iopub.status.busy":"2024-05-19T07:57:09.629404Z","iopub.execute_input":"2024-05-19T07:57:09.629712Z","iopub.status.idle":"2024-05-19T07:57:09.648322Z","shell.execute_reply.started":"2024-05-19T07:57:09.629658Z","shell.execute_reply":"2024-05-19T07:57:09.647612Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# Sequence-to-Sequence Architecture","metadata":{"id":"mq-D4M9eXfaH"}},{"cell_type":"code","source":"class seq2seq(nn.Module):\n  def __init__(self, embedding_size, hidden_size, vocab_size, device, pad_idx, eos_idx, sos_idx):\n    super(seq2seq, self).__init__()\n    \n    # Embedding layer shared by encoder and decoder\n    self.embedding = nn.Embedding(vocab_size, embedding_size)\n    \n    # Encoder network\n    self.encoder = Encoder(hidden_size, \n                            embedding_size,\n                            num_layers=2,\n                            dropout=0.5)\n    \n    # Decoder network        \n    self.decoder = Decoder(embedding_size,\n                            hidden_size,\n                            vocab_size,\n                            n_layers=2,\n                            dropout=0.5)\n    \n    \n    # Indices of special tokens and hardware device \n    self.pad_idx = pad_idx\n    self.eos_idx = eos_idx\n    self.sos_idx = sos_idx\n    self.device = device\n      \n  def create_mask(self, input_sequence):\n    return (input_sequence != self.pad_idx).permute(1, 0)\n      \n      \n  def forward(self, input_sequence, output_sequence):\n    \n    # Unpack input_sequence tuple\n    input_tokens = input_sequence[0]\n  \n    # Unpack output_tokens, or create an empty tensor for text generation\n    if output_sequence is None:\n      inference = True\n      output_tokens = torch.zeros((100, input_tokens.shape[1])).long().fill_(self.sos_idx).to(self.device)\n    else:\n      inference = False\n      output_tokens = output_sequence[0]\n    \n    vocab_size = self.decoder.output_size\n    batch_size = len(input_sequence[1])\n    max_seq_len = len(output_tokens)\n    \n    # tensor to store decoder outputs\n    outputs = torch.zeros(max_seq_len, batch_size, vocab_size).to(self.device)        \n    \n    # pass input sequence to the encoder\n    encoder_outputs, hidden = self.encoder(input_tokens)\n    \n    # first input to the decoder is the <sos> tokens\n    output = output_tokens[0,:]\n    \n    # create mask\n    mask = self.create_mask(input_tokens)\n    \n    \n    # Step through the length of the output sequence one token at a time\n    for t in range(1, max_seq_len):\n      output = output.unsqueeze(0)\n      \n      output, hidden = self.decoder(output, hidden, encoder_outputs, mask)\n      outputs[t] = output\n      \n      if inference:\n        output = output.max(1)[1]\n      else:\n        output = output_tokens[t]\n      \n      # If we're in inference mode, keep generating until we produce an\n      # <eos> token\n      if inference and output.item() == self.eos_idx:\n        return outputs[:t]\n        \n    return outputs","metadata":{"id":"qtZk_bZuf4T3","executionInfo":{"status":"ok","timestamp":1597608683291,"user_tz":-330,"elapsed":1191,"user":{"displayName":"Prateek Joshi","photoUrl":"","userId":"14172408186104425556"}},"execution":{"iopub.status.busy":"2024-05-19T07:57:09.650192Z","iopub.execute_input":"2024-05-19T07:57:09.650615Z","iopub.status.idle":"2024-05-19T07:57:09.664483Z","shell.execute_reply.started":"2024-05-19T07:57:09.650580Z","shell.execute_reply":"2024-05-19T07:57:09.663549Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# Train Seq2Seq Model","metadata":{"id":"vI9kEQOyX67O"}},{"cell_type":"code","source":"# extract special tokens\npad_idx = TRG.vocab.stoi['<pad>']\neos_idx = TRG.vocab.stoi['<eos>']\nsos_idx = TRG.vocab.stoi['<sos>']\n\n# Size of embedding_dim should match the dim of pre-trained word embeddings!\nembedding_dim = 100\nhidden_dim = 256\nvocab_size = len(TRG.vocab)","metadata":{"id":"HTvvFcqegVsB","executionInfo":{"status":"ok","timestamp":1597608737897,"user_tz":-330,"elapsed":1254,"user":{"displayName":"Prateek Joshi","photoUrl":"","userId":"14172408186104425556"}},"execution":{"iopub.status.busy":"2024-05-19T07:57:09.665641Z","iopub.execute_input":"2024-05-19T07:57:09.665958Z","iopub.status.idle":"2024-05-19T07:57:09.676443Z","shell.execute_reply.started":"2024-05-19T07:57:09.665933Z","shell.execute_reply":"2024-05-19T07:57:09.675764Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"model = seq2seq(embedding_dim,\n                hidden_dim, \n                vocab_size, \n                device, pad_idx, eos_idx, sos_idx).to(device)","metadata":{"id":"Bv34kIurggpi","executionInfo":{"status":"ok","timestamp":1597608744952,"user_tz":-330,"elapsed":6030,"user":{"displayName":"Prateek Joshi","photoUrl":"","userId":"14172408186104425556"}},"execution":{"iopub.status.busy":"2024-05-19T07:57:09.677447Z","iopub.execute_input":"2024-05-19T07:57:09.677750Z","iopub.status.idle":"2024-05-19T07:57:14.483337Z","shell.execute_reply.started":"2024-05-19T07:57:09.677712Z","shell.execute_reply":"2024-05-19T07:57:14.482627Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# print model architecture\nmodel","metadata":{"id":"radteBFHgj73","executionInfo":{"status":"ok","timestamp":1597608744957,"user_tz":-330,"elapsed":1331,"user":{"displayName":"Prateek Joshi","photoUrl":"","userId":"14172408186104425556"}},"outputId":"652b91b6-6aa5-4966-db37-c24383324e27","execution":{"iopub.status.busy":"2024-05-19T07:57:14.484541Z","iopub.execute_input":"2024-05-19T07:57:14.484862Z","iopub.status.idle":"2024-05-19T07:57:14.490030Z","shell.execute_reply.started":"2024-05-19T07:57:14.484832Z","shell.execute_reply":"2024-05-19T07:57:14.489187Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"seq2seq(\n  (embedding): Embedding(4004, 100)\n  (encoder): Encoder(\n    (embedding): Embedding(4002, 100)\n    (gru): GRU(100, 256, num_layers=2, dropout=0.5)\n  )\n  (decoder): Decoder(\n    (embedding): Embedding(4004, 100)\n    (gru): GRU(100, 256, num_layers=2, dropout=0.5)\n    (concat): Linear(in_features=512, out_features=256, bias=True)\n    (out): Linear(in_features=256, out_features=4004, bias=True)\n    (attn): Attention()\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Adam optimizer\noptimizer = optim.Adam(model.parameters(), lr=0.01)\n\n# cross entropy loss with softmax\ncriterion = nn.CrossEntropyLoss(ignore_index = pad_idx)","metadata":{"id":"7jXE3me9gmkc","execution":{"iopub.status.busy":"2024-05-19T07:57:14.491200Z","iopub.execute_input":"2024-05-19T07:57:14.491562Z","iopub.status.idle":"2024-05-19T07:57:14.500343Z","shell.execute_reply.started":"2024-05-19T07:57:14.491533Z","shell.execute_reply":"2024-05-19T07:57:14.499640Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def train(model, iterator, criterion, optimizer):\n  # Put the model in training mode!\n  model.train()\n  \n  epoch_loss = 0\n  \n  for idx, batch in notebook.tqdm(enumerate(iterator), total=len(iterator)):\n    input_sequence = batch.rus\n    output_sequence = batch.eng\n\n    target_tokens = output_sequence[0]\n\n    # zero out the gradient for the current batch\n    optimizer.zero_grad()\n\n    # Run the batch through our model\n    output = model(input_sequence, output_sequence)\n\n    # Throw it through our loss function\n    output = output[1:].view(-1, output.shape[-1])\n    target_tokens = target_tokens[1:].view(-1)\n\n    loss = criterion(output, target_tokens)\n\n    # Perform back-prop and calculate the gradient of our loss function\n    loss.backward()\n\n    # Update model parameters\n    optimizer.step()\n\n    epoch_loss += loss.item()\n      \n  return epoch_loss / len(iterator)","metadata":{"id":"cDl-ncAshKsS","execution":{"iopub.status.busy":"2024-05-19T07:57:14.501856Z","iopub.execute_input":"2024-05-19T07:57:14.502254Z","iopub.status.idle":"2024-05-19T07:57:14.510975Z","shell.execute_reply.started":"2024-05-19T07:57:14.502218Z","shell.execute_reply":"2024-05-19T07:57:14.510034Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, iterator, criterion):\n  # Put the model in training mode!\n  model.eval()\n  \n  epoch_loss = 0\n  \n  for idx, batch in notebook.tqdm(enumerate(iterator), total=len(iterator)):\n    input_sequence = batch.rus\n    output_sequence = batch.eng\n\n    target_tokens = output_sequence[0]\n\n    # Run the batch through our model\n    output = model(input_sequence, output_sequence)\n\n    # Throw it through our loss function\n    output = output[1:].view(-1, output.shape[-1])\n    target_tokens = target_tokens[1:].view(-1)\n\n    loss = criterion(output, target_tokens)\n\n    epoch_loss += loss.item()\n      \n  return epoch_loss / len(iterator)","metadata":{"id":"dI0i_3BTxm6y","execution":{"iopub.status.busy":"2024-05-19T07:57:14.512149Z","iopub.execute_input":"2024-05-19T07:57:14.512610Z","iopub.status.idle":"2024-05-19T07:57:14.520609Z","shell.execute_reply.started":"2024-05-19T07:57:14.512533Z","shell.execute_reply":"2024-05-19T07:57:14.519922Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# function to compute time taken by an epoch (in mm:ss)\ndef epoch_time(start_time, end_time):\n  elapsed_time = end_time - start_time\n  elapsed_mins = int(elapsed_time / 60)\n  elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n  return elapsed_mins, elapsed_secs","metadata":{"id":"ES9VLozNycFs","execution":{"iopub.status.busy":"2024-05-19T07:57:14.521769Z","iopub.execute_input":"2024-05-19T07:57:14.522128Z","iopub.status.idle":"2024-05-19T07:57:14.533145Z","shell.execute_reply.started":"2024-05-19T07:57:14.522092Z","shell.execute_reply":"2024-05-19T07:57:14.532499Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"N_EPOCHS = 30\n\nbest_valid_loss = float('inf')\n\n# start model training\nfor epoch in range(N_EPOCHS):\n    \n  start_time = time.time()\n  \n  train_loss = train(model, train_iterator, criterion, optimizer)\n  valid_loss = evaluate(model, valid_iterator, criterion)\n  \n  end_time = time.time()\n  \n  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n  \n  # compare validation loss\n  if valid_loss < best_valid_loss:\n    best_valid_loss = valid_loss\n    torch.save(model.state_dict(), 'best_model.pt')\n  \n  print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n  print(f'\\tTrain Loss: {train_loss:.3f}')\n  print(f'\\t Val. Loss: {valid_loss:.3f}')","metadata":{"id":"P1QF7f0vyb83","executionInfo":{"status":"ok","timestamp":1597606380317,"user_tz":-330,"elapsed":712052,"user":{"displayName":"Prateek Joshi","photoUrl":"","userId":"14172408186104425556"}},"outputId":"1dbda4bb-72bf-444c-e18a-f2456af6b62b","execution":{"iopub.status.busy":"2024-05-19T07:57:14.534224Z","iopub.execute_input":"2024-05-19T07:57:14.534520Z","iopub.status.idle":"2024-05-19T08:02:51.776710Z","shell.execute_reply.started":"2024-05-19T07:57:14.534492Z","shell.execute_reply":"2024-05-19T08:02:51.775346Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2339 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d9da7088ebf4584a5f04408c2f31280"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/585 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e963b6aa9c604ff59d896c8135281be1"}},"metadata":{}},{"name":"stdout","text":"Epoch: 01 | Time: 1m 12s\n\tTrain Loss: 4.700\n\t Val. Loss: 4.649\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2339 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"87f8e009b6154d6eb8fc22774f1d69ea"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/585 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ef019998b2b649bd985613a2d5e1df3f"}},"metadata":{}},{"name":"stdout","text":"Epoch: 02 | Time: 1m 15s\n\tTrain Loss: 4.972\n\t Val. Loss: 4.906\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2339 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5306f88fa1ef46bab86d0ab34344efef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/585 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d7221b7235e4e49a0f789d904375418"}},"metadata":{}},{"name":"stdout","text":"Epoch: 03 | Time: 1m 14s\n\tTrain Loss: 5.103\n\t Val. Loss: 4.991\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2339 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a8db0752758d4304bbfc83102aef2fc0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/585 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e02c8a816ed4e13a1414a67393b91ca"}},"metadata":{}},{"name":"stdout","text":"Epoch: 04 | Time: 1m 13s\n\tTrain Loss: 5.161\n\t Val. Loss: 5.075\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/2339 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4015578b4dcf408f8b4d5a25bf603773"}},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-24-466fab3ecd21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mvalid_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-25e55f7a4b7e>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, iterator, criterion, optimizer)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m# Run the batch through our model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_sequence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# Throw it through our loss function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-16-86c5b96ae8e8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_sequence, output_sequence)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0minference\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"markdown","source":"# Model Inference","metadata":{"id":"aHiAuTovZKS-"}},{"cell_type":"code","source":"# load saved model weights\npath = 'best_model.pt'\nmodel.load_state_dict(torch.load(path))","metadata":{"id":"oe33roXEZXQj","executionInfo":{"status":"ok","timestamp":1597608755127,"user_tz":-330,"elapsed":1297,"user":{"displayName":"Prateek Joshi","photoUrl":"","userId":"14172408186104425556"}},"outputId":"1b9c4563-aace-41ac-ad35-3cbf9a36e34d","execution":{"iopub.status.busy":"2024-05-19T08:02:51.777778Z","iopub.status.idle":"2024-05-19T08:02:51.778241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build Inference Function","metadata":{"id":"W-89TEl8Zbbh"}},{"cell_type":"code","source":"def translate_sentence(model, sentence):\n    model.eval()\n    \n    # tokenization\n    tokenized = nlp_ru(sentence) \n    # convert tokens to lowercase\n    tokenized = [t.lower_ for t in tokenized]\n    # convert tokens to integers\n    int_tokenized = [SRC.vocab.stoi[t] for t in tokenized] \n    \n    # convert list to tensor\n    sentence_length = torch.LongTensor([len(int_tokenized)]).to(model.device) \n    tensor = torch.LongTensor(int_tokenized).unsqueeze(1).to(model.device) \n    \n    # get predictions\n    translation_tensor_logits = model((tensor, sentence_length), None) \n    \n    # get token index with highest score\n    translation_tensor = torch.argmax(translation_tensor_logits.squeeze(1), 1)\n    # convert indices (integers) to tokens\n    translation = [TRG.vocab.itos[t] for t in translation_tensor]\n \n    # Start at the first index.  We don't need to return the <sos> token...\n    translation = translation[1:]\n    return \" \".join(translation)","metadata":{"id":"NNYrl9xuhtK6","executionInfo":{"status":"ok","timestamp":1597608764359,"user_tz":-330,"elapsed":1776,"user":{"displayName":"Prateek Joshi","photoUrl":"","userId":"14172408186104425556"}},"execution":{"iopub.status.busy":"2024-05-19T08:02:51.779781Z","iopub.status.idle":"2024-05-19T08:02:51.780238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentence = \"это новый\"\nresponse = translate_sentence(model, sentence)\nprint(response)","metadata":{"id":"wTn1rIdMva8H","executionInfo":{"status":"ok","timestamp":1597606886808,"user_tz":-330,"elapsed":1782,"user":{"displayName":"Prateek Joshi","photoUrl":"","userId":"14172408186104425556"}},"outputId":"4c59d129-8aa5-459b-d1ae-030aee9d2452","execution":{"iopub.status.busy":"2024-05-19T08:02:51.781282Z","iopub.status.idle":"2024-05-19T08:02:51.781799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Translate Russian Sentences in the Test Dataset","metadata":{"id":"Mz66ziIkZg8X"}},{"cell_type":"code","source":"# read test file \ntest_df = pd.read_csv('../input/englishrussiansentencepairs/data/translation.csv')","metadata":{"id":"wSDfRbWSy8C8","executionInfo":{"status":"ok","timestamp":1597608796965,"user_tz":-330,"elapsed":1683,"user":{"displayName":"Prateek Joshi","photoUrl":"","userId":"14172408186104425556"}},"execution":{"iopub.status.busy":"2024-05-19T08:02:51.782850Z","iopub.status.idle":"2024-05-19T08:02:51.783308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# attention based translations\nattn_translations = [translate_sentence(model, sent) for sent in notebook.tqdm(test_df[\"rus\"])]","metadata":{"id":"HVro9aj8wA8W","executionInfo":{"status":"ok","timestamp":1597609112572,"user_tz":-330,"elapsed":306917,"user":{"displayName":"Prateek Joshi","photoUrl":"","userId":"14172408186104425556"}},"outputId":"9e00f034-5a1c-42e9-8885-d87ea7bd2930","execution":{"iopub.status.busy":"2024-05-19T08:02:51.784399Z","iopub.status.idle":"2024-05-19T08:02:51.784892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[\"attn_translations\"] = attn_translations","metadata":{"id":"INpJsF6SwTN1","executionInfo":{"status":"ok","timestamp":1597609132780,"user_tz":-330,"elapsed":1263,"user":{"displayName":"Prateek Joshi","photoUrl":"","userId":"14172408186104425556"}},"execution":{"iopub.status.busy":"2024-05-19T08:02:51.786055Z","iopub.status.idle":"2024-05-19T08:02:51.786545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check translations\ntest_df.sample(20)","metadata":{"id":"6EaUovPCx9oJ","executionInfo":{"status":"ok","timestamp":1597609140379,"user_tz":-330,"elapsed":1683,"user":{"displayName":"Prateek Joshi","photoUrl":"","userId":"14172408186104425556"}},"outputId":"c69ea8f8-41e6-4c6f-883e-5936c4ba420b","execution":{"iopub.status.busy":"2024-05-19T08:02:51.787753Z","iopub.status.idle":"2024-05-19T08:02:51.788213Z"},"trusted":true},"execution_count":null,"outputs":[]}]}